{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ec6bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (bn0): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=3300, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "MLP(\n",
      "  (bn0): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=3300, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "relevance\n",
      "data: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[0.0583, 0.0577, 0.0366, 0.0366, 0.0361, 0.0337, 0.0283, 0.0283, 0.0274,\n",
      "         0.0274, 0.0272, 0.0203, 0.0202, 0.0202, 0.0199, 0.0191, 0.0190, 0.0146,\n",
      "         0.0146, 0.0130]], dtype=torch.float64),\n",
      "indices=tensor([[1333, 2344, 2141, 1609,  572,  826, 1171, 2332, 1426, 1053, 1209, 1270,\n",
      "          386,  823, 2066,  487, 1154, 1753, 2472, 2437]]))\n",
      "top_k_indices: [[1333, 2344, 2141, 1609, 572, 826, 1171, 2332, 1426, 1053, 1209, 1270, 386, 823, 2066, 487, 1154, 1753, 2472, 2437]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 389\u001b[0m\n\u001b[1;32m    387\u001b[0m top_k_indices\u001b[38;5;241m=\u001b[39mtop_k\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_indices:\u001b[39m\u001b[38;5;124m'\u001b[39m,top_k_indices)\n\u001b[0;32m--> 389\u001b[0m top_k_names\u001b[38;5;241m=\u001b[39m[columns[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m top_k_indices]\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_names:\u001b[39m\u001b[38;5;124m'\u001b[39m,top_k_names)\n\u001b[1;32m    391\u001b[0m contri_k_names\u001b[38;5;241m.\u001b[39mappend(top_k_names)\n",
      "Cell \u001b[0;32mIn[3], line 389\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    387\u001b[0m top_k_indices\u001b[38;5;241m=\u001b[39mtop_k\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_indices:\u001b[39m\u001b[38;5;124m'\u001b[39m,top_k_indices)\n\u001b[0;32m--> 389\u001b[0m top_k_names\u001b[38;5;241m=\u001b[39m[\u001b[43mcolumns\u001b[49m[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m top_k_indices]\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_names:\u001b[39m\u001b[38;5;124m'\u001b[39m,top_k_names)\n\u001b[1;32m    391\u001b[0m contri_k_names\u001b[38;5;241m.\u001b[39mappend(top_k_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import Trainer\n",
    "#from network import NFM\n",
    "import torch.utils.data as Data\n",
    "#from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':2000,\n",
    "    #'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    #'embed_input_dim':1001,#embed输入维度\n",
    "    #'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,8],#MLP隐层\n",
    "    'num_sparse_features_cols':10477,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.5,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 1,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    #'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    #'train_data':'dataset/qiuguan/encode/encode_1000/train/train_encode_data_1000_new.csv',\n",
    "    #'train_label':'dataset/qiuguan/non_code/train/train_label.csv',\n",
    "    #'guan_test_data':'dataset/qiuguan/non_code/guan_test/guan_test_data.csv',\n",
    "    #'guan_test_label':'dataset/qiuguan/non_code/guan_test/guan_test_label.csv',\n",
    "    #'test_data':'dataset/qiuguan/encode/encode_1000/test/test_encode_data_1000_new.csv',\n",
    "    #'test_label':'dataset/qiuguan/non_code/test/test_labels.csv',\n",
    "    #'title':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv',\n",
    "    'gene_name':'dataset/qiuguan/origin_800/gene_name.csv',\n",
    "    'label_name':'dataset/qiuguan/origin_800/gene_label.csv'\n",
    "    #'all':''\n",
    "    #'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    #'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}\n",
    "#model definition\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model = MLP().cuda()\n",
    "print(model)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F  # 激励函数的库\n",
    "#import network\n",
    "#import config\n",
    "#import evaluate\n",
    "#import data_utils\n",
    "#import Trainer\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "class KZDatasetTest(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, csv_path):\n",
    "    \n",
    "        self.data_info = self.get_data_info(csv_path)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data, label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,csv_path):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        df=pd.read_csv(csv_path,sep=',',header=None)\n",
    "        \n",
    "        df=df.iloc[1:,1:]\n",
    "        #print(\"df:\",df)\n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        rows,cols=df.shape\n",
    "        #print(rows,cols)\n",
    "        for i in df.iloc[:,-1]:\n",
    "            #print(i)\n",
    "            labels.append(int(i))\n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #\n",
    "        \n",
    "        for i in range(rows):\n",
    "            data=df.iloc[i,:-1]\n",
    "            data=data.astype(float)##############\n",
    "            #print(\"i,data:\",i,data)\n",
    "            #data=pd.DataFrame(data,dtype=float)###############\n",
    "            data=np.array(data)##\n",
    "            \n",
    "            label=labels[i]\n",
    "            #print(data.shape)\n",
    "            #print(label.shape)\n",
    "            #label=label.tolist()\n",
    "            data=torch.from_numpy(data)#\n",
    "            label=torch.from_numpy(label)#\n",
    "           \n",
    "            \n",
    "            data_info.append((data,label))\n",
    "        return data_info\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import *\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "#######找特征基因#############从3301中找200个基因\n",
    "#########################################################本次测试的目的是看200个基因的分类效果\n",
    "##########测试步骤：从3301个基因中提取350个\n",
    "############用200个构建新的分类模型\n",
    "#################特征基因\n",
    "######################为小球，根据上边的测试的基因个数，350最大\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#from mnist_test import Net, train, test\n",
    "\n",
    "\n",
    "# Network parameters\n",
    "class Params(object):\n",
    "    batch_size = 64\n",
    "    test_batch_size = 20\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    no_cuda = True\n",
    "    seed = 1\n",
    "    log_interval = 10\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "args = Params()\n",
    "torch.manual_seed(args.seed)\n",
    "#device = torch.device(\"cpu\")\n",
    "device=torch.device('cuda')\n",
    "kwargs = {}\n",
    "\n",
    "\n",
    "\n",
    "##############数据准备\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "#path='dataset/qiuguan/model_new_K_fold_RandomTree/MLP_non_encode/MLP9110.pkl'\n",
    "#path='dataset/qiuguan/origin_800/non_encode_aug/para0.4_0.6_0/MLP10210.pkl'\n",
    "path='dataset/qiuguan/origin_800/non_encode_aug/aug_with_simple/para_gause_0.8_0.6/MLP10710.pkl'\n",
    "\n",
    "#path='dataset/qiuguan/origin_800/non_encode_aug/aug_model/para_gause_0.4_0.2_0.6_0.2/MLP7910.pkl'\n",
    "#path='dataset/qiuguan/origin_800/non_encode_aug/aug_et/para_gause_0.8_0.5_gause_0.3_0.1/MLP11012345.pkl'\n",
    "#nfm=NFM(nfm_config)\n",
    "mlp=MLP()\n",
    "#print(nfm)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "mlp.load_state_dict(torch.load(path),strict=False)\n",
    "mlp.cuda()\n",
    "\n",
    "print(mlp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlp_params = list(mlp.named_parameters())\n",
    "#print(nfm_params)\n",
    "net=mlp\n",
    "model=net###########\n",
    "'''\n",
    "testset = KZDatasetTest(csv_path='../NFM-pyorch-master/dataset/qiuguan/orign/')\n",
    "   \n",
    "test_loader = DataLoader(\n",
    "         dataset=testset,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         \n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "'''\n",
    "\n",
    "testset_xiaoqiu  = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/xiaoqiu/test_info.csv')#样本收集特征数据集，和测试数据集不同，这里边可能还包含训练集\n",
    "   \n",
    "test_loader_xiaoqiu = DataLoader(\n",
    "         dataset=testset_xiaoqiu,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         \n",
    "         batch_size=nfm_config['batch_size'],\n",
    "         shuffle=True\n",
    "        \n",
    "     )\n",
    "\n",
    "testset_xiaoguan  = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/xiaoguan/test_info.csv')\n",
    "   \n",
    "test_loader_xiaoguan = DataLoader(\n",
    "         dataset=testset_xiaoguan,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         \n",
    "         batch_size=nfm_config['batch_size'],\n",
    "         shuffle=True\n",
    "        \n",
    "     )\n",
    "import pandas as pd \n",
    "import torch\n",
    "import numpy as np\n",
    "test_df=pd.read_csv('dataset/qiuguan/origin_800/xiaoqiu/test_info.csv',sep=',')\n",
    "test_df=test_df.iloc[:,1:]\n",
    "rows,cols=test_df.shape\n",
    "print(rows,cols)\n",
    "columns=test_df.columns[:-1].tolist()\n",
    "\n",
    "#LRP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline\n",
    "\n",
    "from innvestigator2 import InnvestigateModel\n",
    "#from utils import Flatten\n",
    "model.double()\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "inn_model = InnvestigateModel(model, lrp_exponent=2,\n",
    "                              method=\"e-rule\",\n",
    "                              beta=.5)\n",
    "\n",
    "genes_features=np.array([i for i  in range(9)])#################\n",
    "genes_features=genes_features.reshape(9,1).tolist()#######################genes_features[i][0]=label\n",
    "\n",
    "inn_model.cuda()\n",
    "\n",
    "###[3, 25.353026075712233, tensor([ 182,  879,  103, 2657, 2489,  914, 2437,  180, 2417, 1402, 2344, 2947,\n",
    "###values=tensor([0.0572, 0.0495, 0.0404, 0.0381, 0.0364, 0.0353, 0.0328, 0.0302, 0.0284,\n",
    "#        0.0257, 0.0180, 0.0164, 0.0155, 0.0150, 0.0135, 0.0127, 0.0121, 0.0120,\n",
    "#        0.0114, 0.0107, 0.0107, 0.0104, 0.0100, 0.0100, 0.0099, 0.0091, 0.0091,\n",
    "#       0.0088, 0.0083, 0.0082, 0.0081, 0.0079, 0.0078, 0.0077, 0.0076, 0.0074,\n",
    "#       0.0073, 0.0072, 0.0072, 0.0071], dtype=torch.float64),\n",
    "###indices=tensor([ 182,  879,  103, 2657, 2489,  914, 2437,  180, 2417, 1402, 2344, 2947,\n",
    "#        2546, 1114,  796, 1111, 2472, 2326, 1274,  932, 2476,  716,  989, 3289,\n",
    "#        1252, 2053,  785, 2429, 3015, 1585,  975, 1150, 1155,  726,  823, 2303,\n",
    "#         699,  349, 1792, 1524])), 25.359040192320702, tensor([2489,  826, 1753, 1792,  601, 2303, 1053,  545, 2559,  624, 3256,  762,\n",
    "#        2666,  182, 1881, 1585,  726, 1367, 2405, 1171, 2947, 2093,   14,  265,\n",
    "#         716,  180, 1467, 2207, 3223,  349,  277, 2141, 2878, 2427, 2326, 1111,\n",
    "#         746, 1402, 2150, 1602]), torch.return_types.topk(\n",
    "#values=tensor([0.0456, 0.0445, 0.0406, 0.0349, 0.0277, 0.0273, 0.0246, 0.0236, 0.0225,\n",
    "#        0.0221, 0.0213, 0.0200, 0.0185, 0.0182, 0.0181, 0.0153, 0.0151, 0.0142,\n",
    "##        0.0141, 0.0140, 0.0138, 0.0123, 0.0121, 0.0115, 0.0109, 0.0108, 0.0107,\n",
    "#        0.0102, 0.0102, 0.0098, 0.0094, 0.0093, 0.0092, 0.0089, 0.0082, 0.0081,\n",
    "#        0.0080, 0.0080, 0.0079, 0.0076], dtype=torch.float64),\n",
    "#indices=tensor([2489,  826, 1753, 1792,  601, 2303, 1053,  545, 2559,  624, 3256,  762,\n",
    "#        2666,  182, 1881, 1585,  726, 1367, 2405, 1171, 2947, 2093,   14,  265,\n",
    "#         716,  180, 1467, 2207, 3223,  349,  277, 2141, 2878, 2427, 2326, 1111,\n",
    "#         746, 1402, 2150, 1602]))]\n",
    "\n",
    "for data, target in test_loader_xiaoqiu:############小球\n",
    "\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    #targets=torch.max(targets,1)[1]###################\n",
    "    print('data:',data.shape)\n",
    "    batch_size = int(data.size()[0])\n",
    "    #print('batch_size:',batch_size)#=20\n",
    "    evidence_for_class = []\n",
    "    #print(\"target:\",target.shape)\n",
    "    #print('target:',target[3])\n",
    "    # Overlay with noise \n",
    "    # data[0] += 0.25 * data[0].max() * torch.Tensor(np.random.randn(28*28).reshape(1, 28, 28))\n",
    "    #model_prediction, true_relevance = inn_model.innvestigate(in_tensor=data)\n",
    "    contri_k=[]\n",
    "    contri_k_names=[]\n",
    "    for i in range(9):#10类\n",
    "    # Unfortunately, we had some issue with freeing pytorch memory, therefore \n",
    "    # we need to reevaluate the model separately for every class.\n",
    "        model_prediction, input_relevance_values = inn_model.innvestigate(in_tensor=data)\n",
    "        evidence_for_class.append(input_relevance_values)\n",
    "        top_k=torch.topk(input_relevance_values,20,largest=True)#################20\n",
    "        print('top_k:',top_k)\n",
    "    \n",
    "        contri_k.append(top_k)\n",
    "        top_k_indices=top_k.indices.cpu().detach().numpy().tolist()\n",
    "        print('top_k_indices:',top_k_indices)\n",
    "        top_k_names=[columns[j] for j in top_k_indices]\n",
    "        print('top_k_names:',top_k_names)\n",
    "        contri_k_names.append(top_k_names)\n",
    "        print('contri_k_names:',contri_k_names)\n",
    "        continue\n",
    "    #print('input_relevance_values:',input_relevance_values.shape)\n",
    "    #print('evidence_for_class:',len(evidence_for_class))\n",
    "    evidence_for_class = np.array([elt.numpy() for elt in evidence_for_class])\n",
    "    #print('evidence_for_class:',evidence_for_class.shape)#[10,20,784]\n",
    "    \n",
    "    \n",
    "    for idx, example in enumerate(data):#batch 中的每一个样本\n",
    "        #print('example:',example.shape)\n",
    "        prediction = np.argmax(model_prediction.cpu().detach(), axis=1)#\n",
    "        #print('prediction[idx]:',prediction[idx])\n",
    "        #print(evidence_for_class[prediction[idx]][idx])\n",
    "        #fig, axes = plt.subplots(3, 5)\n",
    "        '''\n",
    "        fig.suptitle(\"Prediction of model: \" + str(prediction[idx]) + \"({0:.2f})\".format(\n",
    "            100*float(model_prediction[idx][model_prediction[idx].argmax()].exp()/model_prediction[idx].exp().sum())))\n",
    "        '''\n",
    "        prediction_value=prediction[idx]\n",
    "        p_x=model_prediction[idx][model_prediction[idx].argmax()].exp()\n",
    "        p_sum=model_prediction[idx].exp().sum()\n",
    "        prediction_score=100*float(model_prediction[idx][model_prediction[idx].argmax()].exp()/model_prediction[idx].exp().sum())\n",
    "        print('prediction_value:',prediction_value)\n",
    "        print('prediction_score:',prediction_score)\n",
    "\n",
    "        continue\n",
    "        #print('分子:',p_x)\n",
    "        #print('分母：',p_sum)\n",
    "        #uu=pr\n",
    "        #print(\"torch.argmax:\",torch.argmax(target[idx]))\n",
    "        if len(genes_features[prediction_value])==1:#有值，但还没有添加预测分数和特征值，只有标签#prediction_value代表第几种疾病\n",
    "            if prediction_value!=torch.argmax(target[idx]).cpu().detach()  :\n",
    "                print('不合格****************:',prediction_value)\n",
    "            if prediction_value==torch.argmax(target[idx]).cpu().detach()  :#预测正确\n",
    "                genes_features[prediction_value].append(prediction_score)\n",
    "                print('合格：',prediction_value)\n",
    "                relevance_score_for_every_pixel=evidence_for_class[prediction[idx]][idx]\n",
    "                #print('relevance_score_for_every_pixel.shape:',relevance_score_for_every_pixel.tolist())\n",
    "                relevance_score_for_every_pixel=torch.from_numpy(relevance_score_for_every_pixel)\n",
    "                index=torch.topk(relevance_score_for_every_pixel,10,largest=True)#基因个数50#####150\n",
    "                #print('pixel_sorted:',index)\n",
    "                genes_features[prediction_value].append(index.indices)#添加前50基因特征\n",
    "                genes_features[prediction_value].append(index)\n",
    "        else: \n",
    "            if genes_features[prediction_value][1]<prediction_score:#如果值比已有值大，说明预测更准确\n",
    "                if prediction_value==torch.argmax(target[idx]).cpu().detach():\n",
    "                    print('&&&&&&&&&&&&&&&&&&&合   格&&&&&&&&&&&&&&:',prediction_value)\n",
    "                    genes_features[prediction_value].pop(3)#删除index\n",
    "                    genes_features[prediction_value].pop(2)#先删除特征值\n",
    "                    genes_features[prediction_value].pop(1)#先删除预测分数\n",
    "                \n",
    "                    genes_features[prediction_value].append(prediction_score)\n",
    "        \n",
    "                    relevance_score_for_every_pixel=evidence_for_class[prediction[idx]][idx]\n",
    "                    #print('relevance_score_for_every_pixel.shape:',relevance_score_for_every_pixel.tolist())\n",
    "                    relevance_score_for_every_pixel=torch.from_numpy(relevance_score_for_every_pixel)\n",
    "                    index=torch.topk(relevance_score_for_every_pixel,10,largest=True)#基因个数50  200\n",
    "                    #print('pixel_sorted:',index)\n",
    "                    genes_features[prediction_value].append(index.indices)\n",
    "                    genes_features[prediction_value].append(index)\n",
    "print('qiu_____genes_features.shape:',genes_features)#######找特征基因#############从3301中找200个基因\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79e8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
