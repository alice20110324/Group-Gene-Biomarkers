{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88aa429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ext_disk/zhenfang/davis/results/model1/without_cross/3/full_model_2_50.pt\n",
      "/media/ext_disk/zhenfang/davis/results/model1/without_cross/3/results.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "root_path = '/media/ext_disk/zhenfang/davis/results/model1/without_cross/'\n",
    "sub_path = '2/'\n",
    "model_file = 'full_model_2_50.pt'\n",
    "\n",
    "#results_save_file='/media/ext_disk/zhenfang/davis/results/model1/without_cross/2/results.txt'\n",
    "results_file='results.txt'\n",
    "\n",
    "\n",
    "\n",
    "sub_path=str(int(sub_path[:-1])+1)+'/'\n",
    "        \n",
    "model_path=os.path.join(root_path, sub_path, model_file)\n",
    "results_save_file=os.path.join(root_path,sub_path,results_file)\n",
    "\n",
    "#results_save_file=os.path.join(root_path,sub_path,model_file)\n",
    "\n",
    "\n",
    "print(model_path)\n",
    "print(results_save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04a6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "import torchmetrics\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecec72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAttMLP_10layers_add__(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 1100)\n",
    "        self.fc11=nn.Linear(1100,1100)\n",
    "        self.bn1 = nn.BatchNorm1d(1100)\n",
    "        self.fc2 = nn.Linear(1100, 100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 9)\n",
    "        self.bn3 = nn.BatchNorm1d(9)\n",
    "\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "        # Conv layers\n",
    "        self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # Change to match input channel 16\n",
    "        self.conv4 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        #self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(3300)\n",
    "        #self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        self.bn5 = nn.BatchNorm1d(3300)\n",
    "        self.pool2 = nn.MaxPool1d(3, stride=3)\n",
    "        #self.conv3 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        self.pool3 = nn.MaxPool1d(3, stride=3)\n",
    "        self.bn6 = nn.BatchNorm1d(1100)\n",
    "        \n",
    "        self.bn7=nn.BatchNorm1d(1100)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=3300)\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=3300)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv1d(16, 16 // 8, 1, padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16 // 8, 16, 1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Define a list to hold multiple layers\n",
    "        self.layers = nn.ModuleList([self._create_layer() for _ in range(2)])\n",
    "\n",
    "    def _create_layer(self):\n",
    "        \"\"\"Create a single layer using conv and pooling operations as defined in the original forward method.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 5, padding=2),\n",
    "            nn.BatchNorm1d(3300),\n",
    "            nn.Conv1d(8, 16, 5, padding=2),\n",
    "            nn.Conv1d(16, 16, 5, padding=2),  # Match input/output channel\n",
    "            nn.Conv1d(16, 1, 1, stride=1),  # This will receive 16 channels and output 1\n",
    "            nn.AvgPool1d(kernel_size=3300),\n",
    "            nn.MaxPool1d(kernel_size=3300)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x1= F.relu(self.drop(self.bn1(self.fc11(self.fc1(x)))))\n",
    "        \n",
    "        \n",
    "        x0 = torch.unsqueeze(x, 1)  # Add a channel dimension\n",
    "        #print('x0:',x0.shape)\n",
    "        # Pass through each layer sequentially\n",
    "        for layer in self.layers:\n",
    "            \n",
    "            x2 = F.relu(layer[0](x0))  # Conv1\n",
    "            x2 = F.relu(layer[2](x2))  # Conv2\n",
    "            avg_pool = self.avg_pool(x2)\n",
    "            avg_out = self.fc(self.avg_pool(x2))\n",
    "            max_pool = self.max_pool(x2)\n",
    "            max_out = self.fc(self.max_pool(x2))\n",
    "            out = avg_out + max_out\n",
    "            x2 = torch.mul(x2, out)\n",
    "            x2 = F.relu(layer[4](x2))  # Conv3\n",
    "            x2 = x0 + x2  # Skip connection\n",
    "            x0 = x2  # Pass to next layer\n",
    "            #print('x0+++:',x0.shape)\n",
    "            \n",
    "        x2=self.pool3(x2)\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=torch.squeeze(x2,1)\n",
    "        x2=self.bn6(x2)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        #x3=torch.concat([x1,x2],dim=1)\n",
    "        #print('x2_final:',x2.shape)\n",
    "        x3=torch.add(x1,x2)\n",
    "        #x3=torch.cat([x1,x2],dim=1)\n",
    "        x4=self.bn7(x3)\n",
    "        x4 = F.relu(self.drop(self.bn2(self.fc2(x4))))\n",
    "        return F.softmax(self.bn3(self.fc3(x4)), dim=1) \n",
    "    \n",
    "#modela=ConvAttMLP_10layers_add__()\n",
    "#modela.cuda()\n",
    "#print(modela)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf74a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAttMLP_10layers_add__LRP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.bn0 = nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 1100)\n",
    "        self.fc11=nn.Linear(1100,1100)\n",
    "        #self.bn1 = nn.BatchNorm1d(1100)\n",
    "        self.fc2 = nn.Linear(1100, 100)\n",
    "        #self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 9)\n",
    "        #self.bn3 = nn.BatchNorm1d(9)\n",
    "\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "        # Conv layers\n",
    "        self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # Change to match input channel 16\n",
    "        self.conv4 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        #self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        #self.bn4 = nn.BatchNorm1d(3300)\n",
    "        #self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        #self.bn5 = nn.BatchNorm1d(3300)\n",
    "        self.pool2 = nn.MaxPool1d(3, stride=3)\n",
    "        #self.conv3 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        self.pool3 = nn.MaxPool1d(3, stride=3)\n",
    "        #self.bn6 = nn.BatchNorm1d(1100)\n",
    "        \n",
    "        #self.bn7=nn.BatchNorm1d(1100)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=3300)\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=3300)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv1d(16, 16 // 8, 1, padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16 // 8, 16, 1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Define a list to hold multiple layers\n",
    "        self.layers = nn.ModuleList([self._create_layer() for _ in range(2)])\n",
    "\n",
    "    def _create_layer(self):\n",
    "        \"\"\"Create a single layer using conv and pooling operations as defined in the original forward method.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 5, padding=2),\n",
    "            nn.BatchNorm1d(3300),\n",
    "            nn.Conv1d(8, 16, 5, padding=2),\n",
    "            nn.Conv1d(16, 16, 5, padding=2),  # Match input/output channel\n",
    "            nn.Conv1d(16, 1, 1, stride=1),  # This will receive 16 channels and output 1\n",
    "            nn.AvgPool1d(kernel_size=3300),\n",
    "            nn.MaxPool1d(kernel_size=3300)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.bn0(x)\n",
    "        x1= F.relu(self.drop(self.bn1(self.fc11(self.fc1(x)))))\n",
    "        \n",
    "        '''\n",
    "        x0 = torch.unsqueeze(x, 1)  # Add a channel dimension\n",
    "        #print('x0:',x0.shape)\n",
    "        # Pass through each layer sequentially\n",
    "        for layer in self.layers:\n",
    "            \n",
    "            x2 = F.relu(layer[0](x0))  # Conv1\n",
    "            x2 = F.relu(layer[2](x2))  # Conv2\n",
    "            avg_pool = self.avg_pool(x2)\n",
    "            avg_out = self.fc(self.avg_pool(x2))\n",
    "            max_pool = self.max_pool(x2)\n",
    "            max_out = self.fc(self.max_pool(x2))\n",
    "            out = avg_out + max_out\n",
    "            x2 = torch.mul(x2, out)\n",
    "            x2 = F.relu(layer[4](x2))  # Conv3\n",
    "            x2 = x0 + x2  # Skip connection\n",
    "            x0 = x2  # Pass to next layer\n",
    "            #print('x0+++:',x0.shape)\n",
    "           \n",
    "        x2=self.pool3(x2)\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=torch.squeeze(x2,1)\n",
    "        x2=self.bn6(x2)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        #x3=torch.concat([x1,x2],dim=1)\n",
    "        #print('x2_final:',x2.shape)\n",
    "        '''\n",
    "        x3=torch.add(x1,x2)\n",
    "        #x3=torch.cat([x1,x2],dim=1)\n",
    "        x4=self.bn7(x3)\n",
    "        x4 = F.relu(self.drop(self.bn2(self.fc2(x4))))\n",
    "        return F.softmax(self.bn3(self.fc3(x4)), dim=1) \n",
    "    \n",
    "#modela=ConvAttMLP_10layers_add__()\n",
    "#modela.cuda()\n",
    "#print(modela)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a111e11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAttMLP_10layers_add(\n",
      "  (bn0): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=3300, out_features=1100, bias=True)\n",
      "  (fc11): Linear(in_features=1100, out_features=1100, bias=True)\n",
      "  (bn1): BatchNorm1d(1100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2200, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (conv1): Conv1d(1, 8, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv2): Conv1d(8, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv4): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bn6): BatchNorm1d(1100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn7): BatchNorm1d(2200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avg_pool): AvgPool1d(kernel_size=(3300,), stride=(3300,), padding=(0,))\n",
      "  (max_pool): MaxPool1d(kernel_size=3300, stride=3300, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Sequential(\n",
      "    (0): Conv1d(16, 2, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv1d(2, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(1, 8, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Conv1d(8, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (4): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
      "      (5): AvgPool1d(kernel_size=(3300,), stride=(3300,), padding=(0,))\n",
      "      (6): MaxPool1d(kernel_size=3300, stride=3300, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv1d(1, 8, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Conv1d(8, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (3): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (4): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
      "      (5): AvgPool1d(kernel_size=(3300,), stride=(3300,), padding=(0,))\n",
      "      (6): MaxPool1d(kernel_size=3300, stride=3300, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvAttMLP_10layers_add(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 1100)\n",
    "        self.fc11=nn.Linear(1100,1100)\n",
    "        self.bn1 = nn.BatchNorm1d(1100)\n",
    "        self.fc2 = nn.Linear(2200, 100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 9)\n",
    "        self.bn3 = nn.BatchNorm1d(9)\n",
    "\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "        # Conv layers\n",
    "        self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # Change to match input channel 16\n",
    "        self.conv4 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        #self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        self.bn4 = nn.BatchNorm1d(3300)\n",
    "        #self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        self.bn5 = nn.BatchNorm1d(3300)\n",
    "        self.pool2 = nn.MaxPool1d(3, stride=3)\n",
    "        #self.conv3 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        self.pool3 = nn.MaxPool1d(3, stride=3)\n",
    "        self.bn6 = nn.BatchNorm1d(1100)\n",
    "        \n",
    "        self.bn7=nn.BatchNorm1d(2200)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=3300)\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=3300)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv1d(16, 16 // 8, 1, padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16 // 8, 16, 1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Define a list to hold multiple layers\n",
    "        self.layers = nn.ModuleList([self._create_layer() for _ in range(2)])\n",
    "\n",
    "    def _create_layer(self):\n",
    "        \"\"\"Create a single layer using conv and pooling operations as defined in the original forward method.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 5, padding=2),\n",
    "            nn.BatchNorm1d(3300),\n",
    "            nn.Conv1d(8, 16, 5, padding=2),\n",
    "            nn.Conv1d(16, 16, 5, padding=2),  # Match input/output channel\n",
    "            nn.Conv1d(16, 1, 1, stride=1),  # This will receive 16 channels and output 1\n",
    "            nn.AvgPool1d(kernel_size=3300),\n",
    "            nn.MaxPool1d(kernel_size=3300)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x1= F.relu(self.drop(self.bn1(self.fc11(self.fc1(x)))))\n",
    "        \n",
    "        \n",
    "        x0 = torch.unsqueeze(x, 1)  # Add a channel dimension\n",
    "        #print('x0:',x0.shape)\n",
    "        # Pass through each layer sequentially\n",
    "        for layer in self.layers:\n",
    "            \n",
    "            x2 = F.relu(layer[0](x0))  # Conv1\n",
    "            x2 = F.relu(layer[2](x2))  # Conv2\n",
    "            avg_pool = self.avg_pool(x2)\n",
    "            avg_out = self.fc(self.avg_pool(x2))\n",
    "            max_pool = self.max_pool(x2)\n",
    "            max_out = self.fc(self.max_pool(x2))\n",
    "            out = avg_out + max_out\n",
    "            x2 = torch.mul(x2, out)\n",
    "            x2 = F.relu(layer[4](x2))  # Conv3\n",
    "            x2 = x0 + x2  # Skip connection\n",
    "            x0 = x2  # Pass to next layer\n",
    "            #print('x0+++:',x0.shape)\n",
    "            \n",
    "        x2=self.pool3(x2)\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=torch.squeeze(x2,1)\n",
    "        x2=self.bn6(x2)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        #x3=torch.concat([x1,x2],dim=1)\n",
    "        #print('x2_final:',x2.shape)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        x3=torch.cat([x1,x2],dim=1)\n",
    "        x4=self.bn7(x3)\n",
    "        x4 = F.relu(self.drop(self.bn2(self.fc2(x4))))\n",
    "        return F.softmax(self.bn3(self.fc3(x4)), dim=1) \n",
    "    \n",
    "modela=ConvAttMLP_10layers_add()\n",
    "modela.cuda()\n",
    "print(modela)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95a214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAttMLP_10layers_add_LRP(\n",
      "  (fc1): Linear(in_features=3300, out_features=1100, bias=True)\n",
      "  (fc11): Linear(in_features=1100, out_features=1100, bias=True)\n",
      "  (fc22): Linear(in_features=1100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvAttMLP_10layers_add_LRP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.bn0 = nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 1100)\n",
    "        self.fc11=nn.Linear(1100,1100)\n",
    "        #self.bn1 = nn.BatchNorm1d(1100)\n",
    "        #self.fc2 = nn.Linear(2200, 100)\n",
    "        self.fc22=nn.Linear(1100,100)\n",
    "        #self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 9)\n",
    "        #self.bn3 = nn.BatchNorm1d(9)\n",
    "\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "        # Conv layers\n",
    "        #self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        #self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        #self.conv3 = nn.Conv1d(16, 16, 5, padding=2)  # Change to match input channel 16\n",
    "        #self.conv4 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        #self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        #self.bn4 = nn.BatchNorm1d(3300)\n",
    "        #self.conv2 = nn.Conv1d(8, 16, 5, padding=2)\n",
    "        #self.bn5 = nn.BatchNorm1d(3300)\n",
    "        #self.pool2 = nn.MaxPool1d(3, stride=3)\n",
    "        #self.conv3 = nn.Conv1d(16, 1, 1, stride=1)\n",
    "        #self.pool3 = nn.MaxPool1d(3, stride=3)\n",
    "        #self.bn6 = nn.BatchNorm1d(1100)\n",
    "        \n",
    "        #self.bn7=nn.BatchNorm1d(2200)\n",
    "        '''\n",
    "        self.avg_pool = nn.AvgPool1d(kernel_size=3300)\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=3300)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv1d(16, 16 // 8, 1, padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16 // 8, 16, 1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Define a list to hold multiple layers\n",
    "        self.layers = nn.ModuleList([self._create_layer() for _ in range(2)])\n",
    "        '''\n",
    "        \n",
    "    ''' \n",
    "    def _create_layer(self):\n",
    "        \"\"\"Create a single layer using conv and pooling operations as defined in the original forward method.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 5, padding=2),\n",
    "            nn.BatchNorm1d(3300),\n",
    "            nn.Conv1d(8, 16, 5, padding=2),\n",
    "            nn.Conv1d(16, 16, 5, padding=2),  # Match input/output channel\n",
    "            nn.Conv1d(16, 1, 1, stride=1),  # This will receive 16 channels and output 1\n",
    "            nn.AvgPool1d(kernel_size=3300),\n",
    "            nn.MaxPool1d(kernel_size=3300)\n",
    "        )\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        print('x:',x.shape)\n",
    "        #x2=x[0,3300:]\n",
    "        #x = self.bn0(x)\n",
    "        #print('x_bn0:',x.shape)\n",
    "        #x2=torch.zeros([1,1100])\n",
    "        #x2=x2.cuda()\n",
    "        #xm=torch.cat([x,x2],dim=1)\n",
    "        \n",
    "        #print('xm.shape:',xm.shape)\n",
    "        x1= F.relu(self.drop(self.fc11(self.fc1(x))))\n",
    "        \n",
    "        \"\"\"\n",
    "        x0 = torch.unsqueeze(x, 1)  # Add a channel dimension\n",
    "        #print('x0:',x0.shape)\n",
    "        # Pass through each layer sequentially\n",
    "        for layer in self.layers:\n",
    "            ）\n",
    "            x2 = F.relu(layer[0](x0))  # Conv1\n",
    "            x2 = F.relu(layer[2](x2))  # Conv2\n",
    "            avg_pool = self.avg_pool(x2)\n",
    "            avg_out = self.fc(self.avg_pool(x2))\n",
    "            max_pool = self.max_pool(x2)\n",
    "            max_out = self.fc(self.max_pool(x2))\n",
    "            out = avg_out + max_out\n",
    "            x2 = torch.mul(x2, out)\n",
    "            x2 = F.relu(layer[4](x2))  # Conv3\n",
    "            x2 = x0 + x2  # Skip connection\n",
    "            x0 = x2  # Pass to next layer\n",
    "            #print('x0+++:',x0.shape)\n",
    "            \n",
    "        x2=self.pool3(x2)\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=torch.squeeze(x2,1)\n",
    "        x2=self.bn6(x2)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        #x3=torch.concat([x1,x2],dim=1)\n",
    "        #print('x2_final:',x2.shape)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        \"\"\"\n",
    "        #print('x1.device:',x1.device)\n",
    "        #x2=torch.zeros([1,1100])\n",
    "        #x2=x2.cuda()\n",
    "        #print('x2.device:',x2.device)\n",
    "        #print('x1.shape:',x1.shape)\n",
    "        #print('x2.shape:',x2.shape)\n",
    "        #x2=torch.squeeze(x2,0)\n",
    "        #print('x2.shape:',x2.shape)\n",
    "        #x3=torch.cat([x1,x2],dim=-1)\n",
    "        #print('x3.shape:',x3.shape)\n",
    "        #x4=self.bn7(x3)\n",
    "        x4 = F.relu(self.drop(self.fc22(x1)))\n",
    "        return F.softmax(self.fc3(x4), dim=-1) \n",
    "    \n",
    "modela=ConvAttMLP_10layers_add_LRP()\n",
    "modela.cuda()\n",
    "print(modela)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f56a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAttMLP_LRP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 1100)\n",
    "        self.bn1= nn.BatchNorm1d(1100)\n",
    "        self.fc2 = nn.Linear(1100, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, 8, 5, padding=2)\n",
    "        #self.pool1 = nn.MaxPool1d(3,stride=3)\n",
    "        self.bn4=nn.BatchNorm1d(3300)\n",
    "        self.conv2 = nn.Conv1d(8, 16, 5,padding=2)\n",
    "        self.bn5=nn.BatchNorm1d(3300)\n",
    "        self.pool2 = nn.MaxPool1d(3,stride=3)\n",
    "        self.conv3=nn.Conv1d(16,1,1,stride=1)\n",
    "        self.pool3=nn.MaxPool1d(3,stride=3)\n",
    "        self.bn6=nn.BatchNorm1d(1100)\n",
    "        #self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        #self.fc3 = nn.Linear(84, 10)\n",
    "        self.bn7=nn.BatchNorm1d(1100)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv1d(16, 16 // 8, 1, padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16 // 8, 16, 1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #x=self.bn0(x)\n",
    "        #print('x:',x.shape)\n",
    "        x1= F.relu(self.drop(self.fc1(x)))\n",
    "        \n",
    "        '''\n",
    "        x0=torch.unsqueeze(x,1)\n",
    "        print(\"x0:\",x0.shape)\n",
    "        \n",
    "        \n",
    "        x2=F.relu(self.conv1(x0))\n",
    "        #x2=x2+x0\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=F.relu(self.conv2(x2))\n",
    "        #x2=x2+x0\n",
    "        #print('x2:',x2.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        avg_out = self.fc(self.avg_pool(x2))\n",
    "        max_out = self.fc(self.max_pool(x2))\n",
    "        out = avg_out + max_out\n",
    "        x2=torch.mul(x2,out)\n",
    "        x2=F.relu(self.conv3(x2))\n",
    "        print('x2:',x2.shape)\n",
    "        #x2=x0+x2\n",
    "        \n",
    "        #print('x2:',x2.shape)\n",
    "        #x2=x0+x2####skip connection\n",
    "        #x2=torch.squeeze(x2,1)\n",
    "        x2=self.bn5(x2)\n",
    "        #x2 = torch.unsqueeze(x2, 1)  # 在第 1 维（通道维）添加维度#####################################\n",
    "        #x2 = self.pool3(x2)  # 现在可以通过 MaxPool1d 了\n",
    "        x2=self.pool3(x2)\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=self.bn6(x2)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        #x3=torch.concat([x1,x2],dim=1)\n",
    "        '''\n",
    "        x2=torch.zeros([1,1100])\n",
    "        x3=torch.add(x1,x2)\n",
    "        #x4=self.bn7(x3)\n",
    "        x4 = F.relu(self.drop(self.fc2(x3)))\n",
    "        return F.softmax(self.fc3(x4), dim=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f112f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP1(\n",
      "  (bn0): BatchNorm1d(237, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=237, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import Trainer\n",
    "#from network import NFM\n",
    "import torch.utils.data as Data\n",
    "#from Utils.criteo_loader import getTestData, getTrainData\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "#import torchmetrics\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':2000,\n",
    "    #'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    #'embed_input_dim':1001,#embed输入维度\n",
    "    #'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,9],#MLP隐层\n",
    "    'num_sparse_features_cols':10477,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.5,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 16,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    #'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    #'train_data':'dataset/qiuguan/encode/encode_1000/train/train_encode_data_1000_new.csv',\n",
    "    #'train_label':'dataset/qiuguan/non_code/train/train_label.csv',\n",
    "    #'guan_test_data':'dataset/qiuguan/non_code/guan_test/guan_test_data.csv',\n",
    "    #'guan_test_label':'dataset/qiuguan/non_code/guan_test/guan_test_label.csv',\n",
    "    #'test_data':'dataset/qiuguan/encode/encode_1000/test/test_encode_data_1000_new.csv',\n",
    "    #'test_label':'dataset/qiuguan/non_code/test/test_labels.csv',\n",
    "    #'title':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv',\n",
    "    \n",
    "    #'all':''\n",
    "    #'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    #'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}\n",
    "\n",
    "#model definition\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model = MLP().cuda()\n",
    "#print(model)\n",
    "\n",
    "class MLP1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(237)\n",
    "        self.fc1 = nn.Linear(237, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model1 = MLP1().cuda()\n",
    "print(model1)\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(126)\n",
    "        self.fc1 = nn.Linear(126, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model2 = MLP2().cuda()\n",
    "#print(model2)\n",
    "\n",
    "\n",
    "class MLP3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(177)\n",
    "        self.fc1 = nn.Linear(177, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model3 = MLP3().cuda()\n",
    "#print(model3)\n",
    "\n",
    "class MLP4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(130)\n",
    "        self.fc1 = nn.Linear(130, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model4 = MLP4().cuda()\n",
    "\n",
    "class MLP5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(172)\n",
    "        self.fc1 = nn.Linear(172, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model5 = MLP5().cuda()\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(model4)\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F  # 激励函数的库\n",
    "#import network\n",
    "#import config\n",
    "#import evaluate\n",
    "#import data_utils\n",
    "#import Trainer\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "class KZDatasetPredict(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, df_list):\n",
    "    \n",
    "       \n",
    "        self.data_info = self.get_data_info(df_list)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data,label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "   \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,df_list):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        #print('data_info:',df_list[-1])\n",
    "        #df=pd.read_csv(csv_path,sep=',')\n",
    "        #df=df.iloc[:,1:]\n",
    "        \n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        label=int(df_list[-1])\n",
    "        labels.append(label)\n",
    "        #print('labels:',labels)\n",
    "        data=df_list[:-1]\n",
    "        #df_np=np.array(df_list)\n",
    "        #print(rows,cols)\n",
    "        \n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        #print('labels.shape:',labels.shape)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        \n",
    "           \n",
    "        \n",
    "        data=np.array(data)#\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        data=torch.from_numpy(data)#\n",
    "            \n",
    "        labels=torch.from_numpy(labels)#\n",
    "        #bi_data=embding_process(nfm_config,data)\n",
    "        #print(\"bi_data.shape:\",bi_data.shape)\n",
    "            \n",
    "            \n",
    "        data_info.append((data,label))\n",
    "        return data_info\n",
    "class KZDatasetTest(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, csv_path):\n",
    "    \n",
    "       \n",
    "        self.data_info = self.get_data_info(csv_path)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data, label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "   \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,csv_path):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        df=pd.read_csv(csv_path,sep=',')\n",
    "        df=df.iloc[:,1:]\n",
    "        \n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        rows,cols=df.shape\n",
    "        print(rows,cols)\n",
    "        for i in df.iloc[:,-1]:\n",
    "            #print(i)\n",
    "            labels.append(int(i))\n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        for i in range(rows):\n",
    "            data=df.iloc[i,:-1]\n",
    "            data=data.astype(float)#\n",
    "            data=np.array(data)#\n",
    "            \n",
    "            label=labels[i]\n",
    "            #print(data.shape)\n",
    "            #print(label.shape)\n",
    "            #label=label.tolist()\n",
    "            data=torch.from_numpy(data)#\n",
    "            label=torch.from_numpy(label)#\n",
    "            \n",
    "            \n",
    "            data_info.append((data,label))\n",
    "        return data_info\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import *\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import torchvision\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "class KZDataset(Dataset):\n",
    "    def __init__(self, csv_path, K,n_class,ki=0, typ='train', transform=None, rand=False):\n",
    "       \n",
    "        self.all_data_info = self.get_data_info(csv_path)\n",
    "        \n",
    "        if rand:\n",
    "            random.seed(1)\n",
    "            random.shuffle(self.all_data_info)\n",
    "        leng = len(self.all_data_info)\n",
    "        every_z_len = leng // K\n",
    "        if typ == 'val':\n",
    "            self.data_info = self.all_data_info[every_z_len * ki : every_z_len * (ki+1)]\n",
    "        elif typ == 'train':\n",
    "            self.data_info = self.all_data_info[: every_z_len * ki] + self.all_data_info[every_z_len * (ki+1) :]\n",
    "            \n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data, label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,csv_path):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        df=pd.read_csv(csv_path,sep=',')\n",
    "        df=df.iloc[:,1:]\n",
    "        \n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        rows,cols=df.shape\n",
    "        \n",
    "        print(rows,cols)\n",
    "        for i in df.iloc[:,-1]:\n",
    "            #print(i)\n",
    "            labels.append(int(i))\n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        for i in range(rows):\n",
    "            data=df.iloc[i,:-1]\n",
    "            data=data.astype(float)#\n",
    "            data=np.array(data)#\n",
    "            \n",
    "            label=labels[i]\n",
    "            #print(data.shape)\n",
    "            #print(label.shape)\n",
    "            #label=label.tolist()\n",
    "            data=torch.from_numpy(data)#\n",
    "            label=torch.from_numpy(label)#\n",
    "            \n",
    "            \n",
    "            data_info.append((data,label))\n",
    "        return data_info\n",
    "    \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "#import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import torchmetrics\n",
    "            \n",
    "\n",
    "from torchmetrics.classification import accuracy\n",
    "\n",
    "def train_epoch(model,train_loader,batch_size,optimizer,loss_func):\n",
    "    BATCH_SIZE=batch_size\n",
    "    total = 0\n",
    "    correct=0\n",
    "    total_loss=0\n",
    "    #\n",
    "    model.train()\n",
    "    total_train_accuracy=0  \n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            \n",
    "        labels = Variable(labels)\n",
    "        x = Variable(x)\n",
    "            \n",
    "            \n",
    "        x=torch.tensor(x,dtype=torch.float)\n",
    "        labels=torch.tensor(labels,dtype=torch.float)\n",
    "        x, labels = x.cuda(), labels.cuda()\n",
    "        labels_int=labels=torch.max(labels,1)[1]\n",
    "            \n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(x)\n",
    "            \n",
    "        loss = loss_func(y_predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss = loss.item()\n",
    "           \n",
    "\n",
    "        total_loss += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        #\n",
    "        '''\n",
    "        train_acc_en=torchmetrics.Accuracy(task='multiclass',num_classes=9).cuda()\n",
    "        batch_train_acc=train_acc_en(y_predict,labels_int)\n",
    "        '''\n",
    "        #batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "        #batch_train_acc=torchmetrics.classification.Accuracy(y_predict,labels_int)\n",
    "        batch_train_acc = torchmetrics.functional.accuracy(y_predict, labels_int, task='multiclass', num_classes=nfm_config['n_class'])\n",
    "        \n",
    "        \n",
    "        #train_acc_en=accuracy(y_predict,labels_int)\n",
    "        #batch_train_acc=train_acc_en()\n",
    "        \n",
    "        total_train_accuracy+=batch_train_acc\n",
    "            \n",
    "    total_train_accuracy/=(batch_idx+1)\n",
    "    print('total_train_accuracy:',total_train_accuracy)\n",
    "    print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total_loss))\n",
    "    return total_loss,total_train_accuracy\n",
    "\n",
    "def val_epoch(model,test_loader,batch_size,optimizer): \n",
    "    batch_size_num=0\n",
    "    total_test_acc=0\n",
    "    model.eval()\n",
    "    for i , (inputs , targets) in enumerate(test_loader):   \n",
    "            print(\"test\")\n",
    "            \n",
    "            inputs = Variable(inputs)   \n",
    "            targets = Variable(targets)     \n",
    "           \n",
    "            inputs=torch.tensor(inputs ,dtype=torch.float)   \n",
    "            targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "            inputs , targets = inputs.cuda(),  targets.cuda()   \n",
    "            yhat = model(inputs)  \n",
    "            \n",
    "            \n",
    "            \n",
    "            targets=torch.max(targets,1)[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            #test_acc_en=torchmetrics.Accuracy(task='multiclass',num_classes=9).cuda()\n",
    "            #batch_test_acc=torchmetrics.functional.accuracy(yhat,targets)\n",
    "            batch_test_acc = torchmetrics.functional.accuracy(yhat, targets, task='multiclass', num_classes=nfm_config['n_class'])\n",
    "            total_test_acc+=batch_test_acc\n",
    "            \n",
    "            batch_size_num=i\n",
    "    total_test_acc/=(batch_size_num+1)\n",
    "        ###print('total_test_accuracy:',total_test_acc/(batch_size+1))\n",
    "    print('total_test_accuracy:',total_test_acc)\n",
    "        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "   \n",
    "    \n",
    "    return total_test_acc\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotLoss(loss,epoch):\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x=[i for i in range(epoch)]\n",
    "    #acc_train=acc_train.cpu()\n",
    "    #acc_test=acc_test.cpu()\n",
    "    plt.plot(x, loss, 'r-', mec='k', label='Logistic Loss', lw=2)\n",
    "    #plt.plot(x,acc_train,'b-',mec='k',label='accuracy Train',lw=2)\n",
    "    #plt.plot(x,acc_test,'g-',mec='k',label='accuracy Test',lw=2)\n",
    "    #plt.plot(x, y_01, 'g-', mec='k', label='0/1 Loss', lw=2)\n",
    "    #plt.plot(x, y_hinge, 'b-',mec='k', label='Hinge Loss', lw=2)\n",
    "    #plt.plot(x, boost, 'm--',mec='k', label='Adaboost Loss',lw=2)\n",
    "    plt.grid(True, ls='--')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('损失函数')\n",
    "    plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1083f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the means for the predicted correctly\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import accuracy_score \n",
    " \n",
    "def bool_predict_model(test_dl, model): \n",
    "    model.eval()#测试数据稳定\n",
    "    error_dataset=torch.tensor([0])\n",
    "    error_dataset=error_dataset.view(1,1)\n",
    "    predictions, actuals = [], [] \n",
    "    num=0\n",
    "    for i, (inputs,targets) in enumerate(test_dl): \n",
    "        # evaluate the model on the test set \n",
    "        #print(\\ inputs:\\ ,inputs) \n",
    "        #print(\\ targets:\\ ,targets) \n",
    "        inputs = Variable(inputs) \n",
    "        #bi_inputs=Variable(bi_inputs)\n",
    "        targets = Variable(targets) \n",
    "        #print(targets)\n",
    "        #print('targets:',targets.shape)        \n",
    "        #targets=targets.argmax(axis=1)  \n",
    "        #print('targets:',targets.shape)\n",
    "        #x = torch.tensor(x, dtype=torch.float) \n",
    "        #x=x.clone().detach().requires_grad_(True) \n",
    "        inputs=torch.tensor(inputs,dtype=torch.float) \n",
    "        #bi_inputs=torch.tensor(bi_inputs,dtype=torch.float)\n",
    "        targets=torch.tensor(targets,dtype=torch.float) \n",
    "        inputs, targets = inputs.cuda(),targets.cuda() \n",
    "        yhat = model(inputs) \n",
    "        \n",
    "        yhat=yhat.argmax(axis=1)\n",
    "        #print('yhat:',yhat.shape)\n",
    "        \n",
    "        if targets==yhat:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "#find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7808a2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18811/4283510531.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/tmp/ipykernel_18811/4283510531.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 3301)\n"
     ]
    }
   ],
   "source": [
    "#find the samples that predicted correctly\n",
    "import pandas as pd \n",
    "test_df=pd.read_csv('dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/test_info1.csv',sep=',')\n",
    "test_df=test_df.iloc[:,1:]\n",
    "rows,cols=test_df.shape\n",
    "#print(rows,cols)\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "path='models/ConvAttMLP_10layers_add//MLP310.pt'\n",
    "\n",
    "#nfm=NFM(nfm_config)\n",
    "#mlp=MLP()\n",
    "model=ConvAttMLP_10layers_add()\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(path), strict=False)\n",
    "'''\n",
    "# 输出模型的参数名和参数形状\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter Name: {name}, Shape: {param.size()}\")\n",
    "'''\n",
    "\n",
    "'''\n",
    "model_lrp=ConvAttMLP_LRP()\n",
    "#print(nfm)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "# Load the state_dict for both models separately\n",
    "model.load_state_dict(torch.load(path), strict=False)\n",
    "model_lrp.load_state_dict(model.state_dict())  # Copying the loaded state dict to model_lrp\n",
    "\n",
    "model.cuda()\n",
    "model_lrp.cuda()\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_params = list(model.named_parameters())\n",
    "#print(nfm_params)\n",
    "net=model\n",
    "'''\n",
    "\n",
    "#testset = KZDatasetPredict(test_df)\n",
    "''''\n",
    "test_loader = data.DataLoader(\n",
    "         dataset=testset,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "'''\n",
    "false_list=[]\n",
    "for i in range(rows):\n",
    "    df_list=test_df.iloc[i,:].tolist()\n",
    "    #print(type(df_list))\n",
    "    #print('df_list:',df_list[-1])\n",
    "    #print(data_set)\n",
    "    #print('this is data_set')\n",
    "    data_set = KZDatasetPredict(df_list)\n",
    "    data_test_loader=data.DataLoader(dataset=data_set,\n",
    "                                    batch_size=1)\n",
    "    #print(data_test_loader)\n",
    "    bool_index=bool_predict_model(data_test_loader,model)\n",
    "    #print(bool_index)\n",
    "    if bool_index==False:\n",
    "        \n",
    "        false_list.append(i)\n",
    "        #test_df=test_df.drop(index=i, inplace=True)\n",
    "        \n",
    "for i,aitem in enumerate(false_list):\n",
    "    test_df.drop(index=i, inplace=True)\n",
    "print(test_df.shape)   \n",
    "\n",
    "test_df.to_csv('dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/ConvAttMLP_10layers_add//test_info3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ae2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18811/1917646279.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  row_mean_tensor=torch.tensor(row_mean_tensor,dtype=torch.float)###################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 0.0000, 0.1229, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.2999e-04, 1.2531e-04, 1.2421e-04, 1.2153e-04, 1.1673e-04, 1.1593e-04,\n",
      "         1.1490e-04, 1.1386e-04, 1.1313e-04, 1.1153e-04, 1.1120e-04, 1.1045e-04,\n",
      "         1.1037e-04, 1.1031e-04, 1.0929e-04, 1.0871e-04, 1.0657e-04, 1.0397e-04,\n",
      "         1.0272e-04, 1.0177e-04, 1.0149e-04, 1.0111e-04, 1.0100e-04, 1.0085e-04,\n",
      "         9.9988e-05, 9.9943e-05, 9.9772e-05, 9.8847e-05, 9.8405e-05, 9.7051e-05,\n",
      "         9.6449e-05, 9.5982e-05, 9.5031e-05, 9.4813e-05, 9.4427e-05, 9.4013e-05,\n",
      "         9.3972e-05, 9.3848e-05, 9.3515e-05, 9.3472e-05, 9.3393e-05, 9.3255e-05,\n",
      "         9.3208e-05, 9.2977e-05, 9.2958e-05, 9.2700e-05, 9.2503e-05, 9.1607e-05,\n",
      "         9.1554e-05, 9.1154e-05, 9.0335e-05, 9.0009e-05, 8.9933e-05, 8.9560e-05,\n",
      "         8.9519e-05, 8.9432e-05, 8.9197e-05, 8.9135e-05, 8.7920e-05, 8.7726e-05,\n",
      "         8.7326e-05, 8.7257e-05, 8.7184e-05, 8.7016e-05, 8.6414e-05, 8.6333e-05,\n",
      "         8.6067e-05, 8.5856e-05, 8.5640e-05, 8.5142e-05, 8.4688e-05, 8.4234e-05,\n",
      "         8.4087e-05, 8.3700e-05, 8.3584e-05, 8.3545e-05, 8.2579e-05, 8.2445e-05,\n",
      "         8.1964e-05, 8.1826e-05, 8.1759e-05, 8.1697e-05, 8.1454e-05, 8.1440e-05,\n",
      "         8.1406e-05, 8.1155e-05, 8.1049e-05, 8.0866e-05, 8.0715e-05, 8.0693e-05,\n",
      "         8.0364e-05, 8.0227e-05, 8.0141e-05, 8.0123e-05, 8.0088e-05, 7.9837e-05,\n",
      "         7.9783e-05, 7.9624e-05, 7.9470e-05, 7.9304e-05]]),\n",
      "indices=tensor([[ 810,  948, 2768,  843, 1037, 1317,   71,  604, 2307, 1630, 2304, 2151,\n",
      "          809, 2493,  883, 3178, 2345, 3129, 2865,  964, 1148,  234, 1930, 2787,\n",
      "         2286, 1223, 2240, 1730, 2935, 1132,  906, 2650, 3149,  334, 1627,    0,\n",
      "         1448, 1198,  928, 1734, 2378, 1464, 3194, 2558, 1811,  131, 1367, 1326,\n",
      "         2111,  781, 2026, 1843, 1635,  602, 3280, 2150,  482,  148,  684, 2958,\n",
      "          434,  858,  280, 3016, 2377, 1208, 3216, 1920, 3126, 3297, 2234,  561,\n",
      "         1993,  254,  988,  829, 1151, 3182, 2194, 1679, 1064,  410, 1916, 1043,\n",
      "         2121,  430, 2473,  893,  727, 2844, 1574, 2130, 2430, 2159, 1795, 2953,\n",
      "         3268, 1442,  211,   40]]))\n",
      "top_k_indices: [[810, 948, 2768, 843, 1037, 1317, 71, 604, 2307, 1630, 2304, 2151, 809, 2493, 883, 3178, 2345, 3129, 2865, 964, 1148, 234, 1930, 2787, 2286, 1223, 2240, 1730, 2935, 1132, 906, 2650, 3149, 334, 1627, 0, 1448, 1198, 928, 1734, 2378, 1464, 3194, 2558, 1811, 131, 1367, 1326, 2111, 781, 2026, 1843, 1635, 602, 3280, 2150, 482, 148, 684, 2958, 434, 858, 280, 3016, 2377, 1208, 3216, 1920, 3126, 3297, 2234, 561, 1993, 254, 988, 829, 1151, 3182, 2194, 1679, 1064, 410, 1916, 1043, 2121, 430, 2473, 893, 727, 2844, 1574, 2130, 2430, 2159, 1795, 2953, 3268, 1442, 211, 40]]\n",
      "top_k_names: ['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 0.1351, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.4291e-04, 1.4108e-04, 1.3293e-04, 1.3236e-04, 1.3125e-04, 1.2997e-04,\n",
      "         1.2847e-04, 1.2752e-04, 1.2441e-04, 1.2343e-04, 1.2306e-04, 1.2195e-04,\n",
      "         1.2150e-04, 1.2135e-04, 1.2108e-04, 1.2020e-04, 1.1681e-04, 1.1404e-04,\n",
      "         1.1349e-04, 1.1341e-04, 1.1170e-04, 1.1163e-04, 1.0999e-04, 1.0931e-04,\n",
      "         1.0900e-04, 1.0897e-04, 1.0856e-04, 1.0806e-04, 1.0792e-04, 1.0785e-04,\n",
      "         1.0749e-04, 1.0719e-04, 1.0651e-04, 1.0513e-04, 1.0382e-04, 1.0337e-04,\n",
      "         1.0301e-04, 1.0285e-04, 1.0260e-04, 1.0239e-04, 1.0132e-04, 1.0127e-04,\n",
      "         1.0127e-04, 1.0102e-04, 1.0052e-04, 1.0029e-04, 1.0002e-04, 9.9999e-05,\n",
      "         9.9979e-05, 9.9772e-05, 9.9700e-05, 9.9593e-05, 9.9488e-05, 9.8896e-05,\n",
      "         9.8892e-05, 9.7369e-05, 9.7173e-05, 9.7059e-05, 9.6655e-05, 9.6532e-05,\n",
      "         9.6309e-05, 9.5943e-05, 9.5901e-05, 9.5893e-05, 9.5773e-05, 9.5207e-05,\n",
      "         9.4923e-05, 9.4651e-05, 9.4492e-05, 9.4445e-05, 9.4438e-05, 9.3928e-05,\n",
      "         9.3872e-05, 9.3633e-05, 9.3065e-05, 9.2962e-05, 9.2777e-05, 9.2088e-05,\n",
      "         9.1650e-05, 9.1575e-05, 9.1538e-05, 9.0604e-05, 9.0497e-05, 8.9267e-05,\n",
      "         8.9244e-05, 8.9174e-05, 8.9040e-05, 8.8960e-05, 8.8949e-05, 8.8803e-05,\n",
      "         8.8653e-05, 8.8636e-05, 8.8415e-05, 8.7976e-05, 8.7936e-05, 8.7778e-05,\n",
      "         8.7713e-05, 8.6984e-05, 8.6689e-05, 8.6656e-05]]),\n",
      "indices=tensor([[ 810,  948, 1037,  843, 2768, 1317,  604, 2304, 2307,  883,   71, 1630,\n",
      "         2493, 2151, 2345, 3178, 3129,  964,  809, 1148, 2286, 1223,  234, 1730,\n",
      "         2650, 1930, 2240, 2865,  928, 2935, 2787,  906, 2378, 1132, 1811, 1627,\n",
      "         3149, 1448, 1367,    0, 1198,  781, 2558, 1635, 1326, 3194, 2111,  334,\n",
      "         1843, 1734, 1464, 2026,  131, 2377,  602, 2958, 3126,  482, 3280, 2150,\n",
      "          280, 3216, 3297, 2234,  858, 1208,  148,  434,  684, 3016, 1920, 1151,\n",
      "          410,  254, 1679,  988,  561, 3182, 1993,  430, 2121,  893,  829, 2953,\n",
      "         2844, 2473, 1020, 2194, 3195, 2235, 1043,  727, 2656, 1916, 1983,  565,\n",
      "         1795, 1354, 1325, 1064]]))\n",
      "top_k_indices: [[810, 948, 1037, 843, 2768, 1317, 604, 2304, 2307, 883, 71, 1630, 2493, 2151, 2345, 3178, 3129, 964, 809, 1148, 2286, 1223, 234, 1730, 2650, 1930, 2240, 2865, 928, 2935, 2787, 906, 2378, 1132, 1811, 1627, 3149, 1448, 1367, 0, 1198, 781, 2558, 1635, 1326, 3194, 2111, 334, 1843, 1734, 1464, 2026, 131, 2377, 602, 2958, 3126, 482, 3280, 2150, 280, 3216, 3297, 2234, 858, 1208, 148, 434, 684, 3016, 1920, 1151, 410, 254, 1679, 988, 561, 3182, 1993, 430, 2121, 893, 829, 2953, 2844, 2473, 1020, 2194, 3195, 2235, 1043, 727, 2656, 1916, 1983, 565, 1795, 1354, 1325, 1064]]\n",
      "top_k_names: ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 0.0000, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.4759e-04, 1.4000e-04, 1.3492e-04, 1.3491e-04, 1.3445e-04, 1.2967e-04,\n",
      "         1.2959e-04, 1.2840e-04, 1.2663e-04, 1.2656e-04, 1.2558e-04, 1.2530e-04,\n",
      "         1.2426e-04, 1.2405e-04, 1.2383e-04, 1.2309e-04, 1.1972e-04, 1.1576e-04,\n",
      "         1.1522e-04, 1.1489e-04, 1.1294e-04, 1.1262e-04, 1.1260e-04, 1.1132e-04,\n",
      "         1.1100e-04, 1.1074e-04, 1.1015e-04, 1.0999e-04, 1.0949e-04, 1.0893e-04,\n",
      "         1.0884e-04, 1.0842e-04, 1.0748e-04, 1.0744e-04, 1.0742e-04, 1.0691e-04,\n",
      "         1.0447e-04, 1.0386e-04, 1.0351e-04, 1.0329e-04, 1.0329e-04, 1.0319e-04,\n",
      "         1.0308e-04, 1.0249e-04, 1.0233e-04, 1.0198e-04, 1.0195e-04, 1.0186e-04,\n",
      "         1.0174e-04, 1.0116e-04, 1.0081e-04, 1.0063e-04, 1.0018e-04, 1.0001e-04,\n",
      "         9.9880e-05, 9.9560e-05, 9.9175e-05, 9.8992e-05, 9.8990e-05, 9.8731e-05,\n",
      "         9.8060e-05, 9.7864e-05, 9.7728e-05, 9.7560e-05, 9.7292e-05, 9.6045e-05,\n",
      "         9.5914e-05, 9.5768e-05, 9.5722e-05, 9.5461e-05, 9.5251e-05, 9.5049e-05,\n",
      "         9.5001e-05, 9.4888e-05, 9.4608e-05, 9.4032e-05, 9.3851e-05, 9.3722e-05,\n",
      "         9.3583e-05, 9.2659e-05, 9.2374e-05, 9.2166e-05, 9.1758e-05, 9.1411e-05,\n",
      "         9.1408e-05, 9.0628e-05, 9.0567e-05, 9.0044e-05, 8.9879e-05, 8.9756e-05,\n",
      "         8.9714e-05, 8.9626e-05, 8.9610e-05, 8.9460e-05, 8.9184e-05, 8.8900e-05,\n",
      "         8.8890e-05, 8.8874e-05, 8.8830e-05, 8.8534e-05]]),\n",
      "indices=tensor([[ 810,  948, 2768, 1037,  843, 2304, 1317,  604, 2307,   71,  883, 2151,\n",
      "         2345, 1630, 2493, 3178, 3129,  964,  809, 1148, 2286, 1223,  234, 2787,\n",
      "         2240, 2935, 2865, 2650, 1930,  906,  928, 1730, 1811, 2378, 3149, 1132,\n",
      "         1448,    0, 1627, 1198, 1367, 2026, 3194, 1635,  334,  602,  781, 1464,\n",
      "         2558,  131, 1326, 1734, 2377, 1843, 3126, 2111, 2958, 3280,  148, 2150,\n",
      "          684,  482,  434, 3216,  280,  858, 1208, 3182, 3297,  410,  988, 2234,\n",
      "         3016,  561,  254, 1151, 1679, 1920, 2121, 1993, 2473,  829,  430, 1020,\n",
      "         2235,  893, 1043, 2194, 3195,  727, 2953, 2844, 3268, 2130, 1983, 2775,\n",
      "          565, 2159, 1795, 1354]]))\n",
      "top_k_indices: [[810, 948, 2768, 1037, 843, 2304, 1317, 604, 2307, 71, 883, 2151, 2345, 1630, 2493, 3178, 3129, 964, 809, 1148, 2286, 1223, 234, 2787, 2240, 2935, 2865, 2650, 1930, 906, 928, 1730, 1811, 2378, 3149, 1132, 1448, 0, 1627, 1198, 1367, 2026, 3194, 1635, 334, 602, 781, 1464, 2558, 131, 1326, 1734, 2377, 1843, 3126, 2111, 2958, 3280, 148, 2150, 684, 482, 434, 3216, 280, 858, 1208, 3182, 3297, 410, 988, 2234, 3016, 561, 254, 1151, 1679, 1920, 2121, 1993, 2473, 829, 430, 1020, 2235, 893, 1043, 2194, 3195, 727, 2953, 2844, 3268, 2130, 1983, 2775, 565, 2159, 1795, 1354]]\n",
      "top_k_names: ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1'], ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 0.0000, 0.1544, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.5987e-04, 1.5956e-04, 1.5586e-04, 1.5105e-04, 1.4702e-04, 1.4521e-04,\n",
      "         1.4493e-04, 1.4406e-04, 1.4272e-04, 1.4235e-04, 1.4211e-04, 1.4036e-04,\n",
      "         1.3948e-04, 1.3860e-04, 1.3818e-04, 1.3757e-04, 1.3611e-04, 1.3342e-04,\n",
      "         1.3098e-04, 1.2951e-04, 1.2855e-04, 1.2697e-04, 1.2591e-04, 1.2580e-04,\n",
      "         1.2451e-04, 1.2419e-04, 1.2409e-04, 1.2407e-04, 1.2269e-04, 1.2161e-04,\n",
      "         1.2101e-04, 1.2066e-04, 1.2060e-04, 1.1997e-04, 1.1948e-04, 1.1920e-04,\n",
      "         1.1888e-04, 1.1866e-04, 1.1738e-04, 1.1725e-04, 1.1704e-04, 1.1697e-04,\n",
      "         1.1626e-04, 1.1427e-04, 1.1424e-04, 1.1412e-04, 1.1405e-04, 1.1386e-04,\n",
      "         1.1385e-04, 1.1357e-04, 1.1330e-04, 1.1329e-04, 1.1324e-04, 1.1284e-04,\n",
      "         1.1258e-04, 1.1236e-04, 1.1200e-04, 1.1199e-04, 1.1186e-04, 1.1180e-04,\n",
      "         1.1091e-04, 1.1074e-04, 1.1014e-04, 1.0932e-04, 1.0818e-04, 1.0803e-04,\n",
      "         1.0792e-04, 1.0771e-04, 1.0696e-04, 1.0671e-04, 1.0600e-04, 1.0512e-04,\n",
      "         1.0511e-04, 1.0468e-04, 1.0410e-04, 1.0388e-04, 1.0357e-04, 1.0346e-04,\n",
      "         1.0342e-04, 1.0332e-04, 1.0317e-04, 1.0275e-04, 1.0243e-04, 1.0211e-04,\n",
      "         1.0206e-04, 1.0196e-04, 1.0193e-04, 1.0185e-04, 1.0113e-04, 1.0105e-04,\n",
      "         1.0085e-04, 1.0035e-04, 1.0022e-04, 1.0006e-04, 1.0002e-04, 9.9943e-05,\n",
      "         9.9844e-05, 9.9784e-05, 9.9726e-05, 9.9115e-05]]),\n",
      "indices=tensor([[ 948,  810, 2768,  843, 2304, 1037,   71,  604, 1630, 1317, 2307,  883,\n",
      "         2345, 2151,  809, 2493, 3178, 2865, 3129, 2240,  964,  234, 2286, 1148,\n",
      "         1223, 2935, 1730,  928, 2650, 1930,  906, 3149, 2787, 1811, 2026, 1132,\n",
      "         3194, 1464,    0, 2378, 1367, 1627, 1448, 1198, 2558, 1734, 1635,  781,\n",
      "          482, 3280, 2377, 1843,  602, 1326, 2111,  334, 3016,  148,  684, 2958,\n",
      "          280,  131, 2150, 3297, 3126,  434, 1920,  858, 3216,  561,  254,  988,\n",
      "          410, 1208, 2234,  430, 2121, 3268, 3182, 1064, 1993, 2473, 1043, 2430,\n",
      "         2844,  829, 1795, 2194,  211, 1151, 1574, 1325, 1679, 2130, 3195, 2105,\n",
      "         2775, 2235,  893,  727]]))\n",
      "top_k_indices: [[948, 810, 2768, 843, 2304, 1037, 71, 604, 1630, 1317, 2307, 883, 2345, 2151, 809, 2493, 3178, 2865, 3129, 2240, 964, 234, 2286, 1148, 1223, 2935, 1730, 928, 2650, 1930, 906, 3149, 2787, 1811, 2026, 1132, 3194, 1464, 0, 2378, 1367, 1627, 1448, 1198, 2558, 1734, 1635, 781, 482, 3280, 2377, 1843, 602, 1326, 2111, 334, 3016, 148, 684, 2958, 280, 131, 2150, 3297, 3126, 434, 1920, 858, 3216, 561, 254, 988, 410, 1208, 2234, 430, 2121, 3268, 3182, 1064, 1993, 2473, 1043, 2430, 2844, 829, 1795, 2194, 211, 1151, 1574, 1325, 1679, 2130, 3195, 2105, 2775, 2235, 893, 727]]\n",
      "top_k_names: ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'GPX3', 'MT1G', 'RPS24', 'ACTG1', 'ATP5F1A', 'MT2A', 'ITM2B', 'RPL5', 'LDHB', 'MYL6', 'RPS16', 'RPL8', 'RPL15', 'IGFBP7', 'SELENOP', 'CAPN2', 'RPL38', 'RTN4', 'CD63', 'ATP5F1C', 'TMBIM6', 'HNRNPK', 'VIM', 'CRYAB', 'SRP9', 'ATP5PO', 'SOD1', 'NOP53', 'ISCU', 'S100A10', 'GHITM', 'SUCLG1', 'ATP5F1B', 'NACA4P', 'RHOA', 'ALDOB', 'NDUFB1', 'GNAS', 'NDUFB2', 'ALDH2', 'SPCS1', 'SEC61B', 'NEDD8', 'AKR1A1', 'A2M', 'NDUFB3', 'ALDH9A1', 'ECH1', 'ACTB', 'BHMT', 'RAC1', 'GABARAP', 'MT1F', 'UMOD', 'ADI1', 'NDUFA1', 'CCT8', 'PTGES3', 'COX8A', 'AMOT', 'GATM', 'MGP', 'DAD1', 'GADD45A', 'KARS', 'ACADVL', 'ATP5PF', 'PSMB1', 'SARAF', 'PSMA6', 'CLTA', 'HADHB', 'HSD17B12', 'UQCR10', 'TST', 'PEBP1', 'GSTO1', 'PSMB5', 'TMEM147', 'SDC4', 'S100A6', 'LTA4H', 'PHB2', 'TPI1', 'ADH5', 'RHOC', 'COX5B', 'ALDOA', 'SERINC1', 'SLC38A2', 'TUBB2A', 'YPEL5', 'FOXC1', 'MRPL49', 'PEPD', 'AGMAT']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1'], ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'GPX3', 'MT1G', 'RPS24', 'ACTG1', 'ATP5F1A', 'MT2A', 'ITM2B', 'RPL5', 'LDHB', 'MYL6', 'RPS16', 'RPL8', 'RPL15', 'IGFBP7', 'SELENOP', 'CAPN2', 'RPL38', 'RTN4', 'CD63', 'ATP5F1C', 'TMBIM6', 'HNRNPK', 'VIM', 'CRYAB', 'SRP9', 'ATP5PO', 'SOD1', 'NOP53', 'ISCU', 'S100A10', 'GHITM', 'SUCLG1', 'ATP5F1B', 'NACA4P', 'RHOA', 'ALDOB', 'NDUFB1', 'GNAS', 'NDUFB2', 'ALDH2', 'SPCS1', 'SEC61B', 'NEDD8', 'AKR1A1', 'A2M', 'NDUFB3', 'ALDH9A1', 'ECH1', 'ACTB', 'BHMT', 'RAC1', 'GABARAP', 'MT1F', 'UMOD', 'ADI1', 'NDUFA1', 'CCT8', 'PTGES3', 'COX8A', 'AMOT', 'GATM', 'MGP', 'DAD1', 'GADD45A', 'KARS', 'ACADVL', 'ATP5PF', 'PSMB1', 'SARAF', 'PSMA6', 'CLTA', 'HADHB', 'HSD17B12', 'UQCR10', 'TST', 'PEBP1', 'GSTO1', 'PSMB5', 'TMEM147', 'SDC4', 'S100A6', 'LTA4H', 'PHB2', 'TPI1', 'ADH5', 'RHOC', 'COX5B', 'ALDOA', 'SERINC1', 'SLC38A2', 'TUBB2A', 'YPEL5', 'FOXC1', 'MRPL49', 'PEPD', 'AGMAT']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1377, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.4607e-04, 1.4415e-04, 1.3504e-04, 1.3488e-04, 1.3403e-04, 1.3108e-04,\n",
      "         1.3058e-04, 1.2819e-04, 1.2806e-04, 1.2724e-04, 1.2464e-04, 1.2440e-04,\n",
      "         1.2409e-04, 1.2385e-04, 1.2357e-04, 1.2276e-04, 1.1809e-04, 1.1686e-04,\n",
      "         1.1541e-04, 1.1532e-04, 1.1493e-04, 1.1247e-04, 1.1171e-04, 1.1158e-04,\n",
      "         1.1107e-04, 1.1101e-04, 1.1087e-04, 1.1017e-04, 1.1006e-04, 1.0988e-04,\n",
      "         1.0869e-04, 1.0833e-04, 1.0809e-04, 1.0771e-04, 1.0604e-04, 1.0556e-04,\n",
      "         1.0537e-04, 1.0499e-04, 1.0493e-04, 1.0348e-04, 1.0339e-04, 1.0318e-04,\n",
      "         1.0305e-04, 1.0293e-04, 1.0279e-04, 1.0271e-04, 1.0258e-04, 1.0235e-04,\n",
      "         1.0232e-04, 1.0220e-04, 1.0204e-04, 1.0201e-04, 1.0188e-04, 1.0149e-04,\n",
      "         1.0015e-04, 9.9200e-05, 9.8689e-05, 9.8565e-05, 9.8408e-05, 9.8337e-05,\n",
      "         9.8121e-05, 9.7820e-05, 9.7645e-05, 9.7587e-05, 9.7190e-05, 9.7001e-05,\n",
      "         9.6796e-05, 9.6745e-05, 9.6504e-05, 9.6202e-05, 9.5493e-05, 9.5286e-05,\n",
      "         9.4902e-05, 9.4767e-05, 9.4696e-05, 9.4563e-05, 9.4520e-05, 9.4323e-05,\n",
      "         9.3741e-05, 9.2828e-05, 9.2660e-05, 9.2537e-05, 9.2250e-05, 9.1665e-05,\n",
      "         9.0811e-05, 9.0593e-05, 9.0556e-05, 9.0523e-05, 9.0484e-05, 9.0431e-05,\n",
      "         9.0320e-05, 9.0216e-05, 8.9848e-05, 8.9686e-05, 8.9608e-05, 8.9519e-05,\n",
      "         8.9325e-05, 8.9271e-05, 8.8757e-05, 8.8568e-05]]),\n",
      "indices=tensor([[ 810,  948,  843, 2768, 1037, 1317,  604,   71, 2304, 2307, 2493, 2151,\n",
      "         1630,  883, 2345, 3178, 3129,  809, 1223,  964, 1148, 2286, 1930,  234,\n",
      "         1730, 2865, 2240, 2787,  906, 2650, 2935, 1132,  928, 2378, 1811, 1448,\n",
      "         3149, 1627,    0, 2558, 1198,  781,  334, 1326, 1635, 1367, 1734, 3194,\n",
      "         1843, 1464,  131, 2111, 2026,  602, 2377, 2150,  482,  280, 2958, 3126,\n",
      "          148, 3280, 3216,  434, 1208, 2234, 3297,  684,  858, 1920, 3016, 1151,\n",
      "          561,  988,  254, 1679,  410, 1993, 3182, 2121,  829,  430,  893, 2473,\n",
      "          727, 1916, 2953, 2194, 3195, 2844, 1043, 1020,  565, 2656, 2235, 1983,\n",
      "         1795, 2159, 2352, 1354]]))\n",
      "top_k_indices: [[810, 948, 843, 2768, 1037, 1317, 604, 71, 2304, 2307, 2493, 2151, 1630, 883, 2345, 3178, 3129, 809, 1223, 964, 1148, 2286, 1930, 234, 1730, 2865, 2240, 2787, 906, 2650, 2935, 1132, 928, 2378, 1811, 1448, 3149, 1627, 0, 2558, 1198, 781, 334, 1326, 1635, 1367, 1734, 3194, 1843, 1464, 131, 2111, 2026, 602, 2377, 2150, 482, 280, 2958, 3126, 148, 3280, 3216, 434, 1208, 2234, 3297, 684, 858, 1920, 3016, 1151, 561, 988, 254, 1679, 410, 1993, 3182, 2121, 829, 430, 893, 2473, 727, 1916, 2953, 2194, 3195, 2844, 1043, 1020, 565, 2656, 2235, 1983, 1795, 2159, 2352, 1354]]\n",
      "top_k_names: ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'MT2A', 'ACTG1', 'RPS24', 'GPX3', 'ITM2B', 'RPL8', 'MYL6', 'ATP5F1A', 'RPL5', 'LDHB', 'RPL15', 'SELENOP', 'RPS16', 'TMBIM6', 'RPL38', 'ATP5F1C', 'CD63', 'ATP5PO', 'RTN4', 'VIM', 'IGFBP7', 'CAPN2', 'ISCU', 'SOD1', 'SRP9', 'HNRNPK', 'SUCLG1', 'CRYAB', 'ALDOB', 'S100A10', 'NDUFB2', 'NOP53', 'GNAS', 'RHOA', 'SPCS1', 'ALDH2', 'AKR1A1', 'GABARAP', 'BHMT', 'NEDD8', 'NDUFB1', 'SEC61B', 'ATP5F1B', 'ECH1', 'NACA4P', 'PTGES3', 'RAC1', 'GHITM', 'ACTB', 'ALDH9A1', 'COX8A', 'A2M', 'CCT8', 'NDUFA1', 'GATM', 'UMOD', 'NDUFB3', 'KARS', 'MGP', 'PSMA6', 'CLTA', 'AMOT', 'ADI1', 'GADD45A', 'DAD1', 'MT1F', 'RHOC', 'ACADVL', 'PSMB1', 'ATP5PF', 'SERINC1', 'SARAF', 'GSTO1', 'TST', 'HSD17B12', 'LTA4H', 'HADHB', 'PEPD', 'PSMB5', 'AGMAT', 'YWHAZ', 'SGK1', 'TPI1', 'TUBB2A', 'S100A6', 'TMEM147', 'TMED9', 'ACAT1', 'EIF4G2', 'MRPL49', 'PHYH', 'PHB2', 'CAPNS1', 'ANXA7', 'H2AFZ']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1'], ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'GPX3', 'MT1G', 'RPS24', 'ACTG1', 'ATP5F1A', 'MT2A', 'ITM2B', 'RPL5', 'LDHB', 'MYL6', 'RPS16', 'RPL8', 'RPL15', 'IGFBP7', 'SELENOP', 'CAPN2', 'RPL38', 'RTN4', 'CD63', 'ATP5F1C', 'TMBIM6', 'HNRNPK', 'VIM', 'CRYAB', 'SRP9', 'ATP5PO', 'SOD1', 'NOP53', 'ISCU', 'S100A10', 'GHITM', 'SUCLG1', 'ATP5F1B', 'NACA4P', 'RHOA', 'ALDOB', 'NDUFB1', 'GNAS', 'NDUFB2', 'ALDH2', 'SPCS1', 'SEC61B', 'NEDD8', 'AKR1A1', 'A2M', 'NDUFB3', 'ALDH9A1', 'ECH1', 'ACTB', 'BHMT', 'RAC1', 'GABARAP', 'MT1F', 'UMOD', 'ADI1', 'NDUFA1', 'CCT8', 'PTGES3', 'COX8A', 'AMOT', 'GATM', 'MGP', 'DAD1', 'GADD45A', 'KARS', 'ACADVL', 'ATP5PF', 'PSMB1', 'SARAF', 'PSMA6', 'CLTA', 'HADHB', 'HSD17B12', 'UQCR10', 'TST', 'PEBP1', 'GSTO1', 'PSMB5', 'TMEM147', 'SDC4', 'S100A6', 'LTA4H', 'PHB2', 'TPI1', 'ADH5', 'RHOC', 'COX5B', 'ALDOA', 'SERINC1', 'SLC38A2', 'TUBB2A', 'YPEL5', 'FOXC1', 'MRPL49', 'PEPD', 'AGMAT'], ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'MT2A', 'ACTG1', 'RPS24', 'GPX3', 'ITM2B', 'RPL8', 'MYL6', 'ATP5F1A', 'RPL5', 'LDHB', 'RPL15', 'SELENOP', 'RPS16', 'TMBIM6', 'RPL38', 'ATP5F1C', 'CD63', 'ATP5PO', 'RTN4', 'VIM', 'IGFBP7', 'CAPN2', 'ISCU', 'SOD1', 'SRP9', 'HNRNPK', 'SUCLG1', 'CRYAB', 'ALDOB', 'S100A10', 'NDUFB2', 'NOP53', 'GNAS', 'RHOA', 'SPCS1', 'ALDH2', 'AKR1A1', 'GABARAP', 'BHMT', 'NEDD8', 'NDUFB1', 'SEC61B', 'ATP5F1B', 'ECH1', 'NACA4P', 'PTGES3', 'RAC1', 'GHITM', 'ACTB', 'ALDH9A1', 'COX8A', 'A2M', 'CCT8', 'NDUFA1', 'GATM', 'UMOD', 'NDUFB3', 'KARS', 'MGP', 'PSMA6', 'CLTA', 'AMOT', 'ADI1', 'GADD45A', 'DAD1', 'MT1F', 'RHOC', 'ACADVL', 'PSMB1', 'ATP5PF', 'SERINC1', 'SARAF', 'GSTO1', 'TST', 'HSD17B12', 'LTA4H', 'HADHB', 'PEPD', 'PSMB5', 'AGMAT', 'YWHAZ', 'SGK1', 'TPI1', 'TUBB2A', 'S100A6', 'TMEM147', 'TMED9', 'ACAT1', 'EIF4G2', 'MRPL49', 'PHYH', 'PHB2', 'CAPNS1', 'ANXA7', 'H2AFZ']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 0.0000, 0.1365, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.4594e-04, 1.3882e-04, 1.3436e-04, 1.3249e-04, 1.3247e-04, 1.2946e-04,\n",
      "         1.2853e-04, 1.2838e-04, 1.2661e-04, 1.2536e-04, 1.2321e-04, 1.2203e-04,\n",
      "         1.2189e-04, 1.2172e-04, 1.2106e-04, 1.2105e-04, 1.2101e-04, 1.1587e-04,\n",
      "         1.1523e-04, 1.1391e-04, 1.1352e-04, 1.1235e-04, 1.1214e-04, 1.1113e-04,\n",
      "         1.1112e-04, 1.1009e-04, 1.0894e-04, 1.0876e-04, 1.0738e-04, 1.0675e-04,\n",
      "         1.0662e-04, 1.0655e-04, 1.0523e-04, 1.0479e-04, 1.0450e-04, 1.0442e-04,\n",
      "         1.0430e-04, 1.0400e-04, 1.0384e-04, 1.0372e-04, 1.0321e-04, 1.0319e-04,\n",
      "         1.0293e-04, 1.0276e-04, 1.0264e-04, 1.0231e-04, 1.0158e-04, 1.0154e-04,\n",
      "         1.0150e-04, 1.0133e-04, 1.0053e-04, 1.0051e-04, 1.0038e-04, 1.0034e-04,\n",
      "         1.0026e-04, 9.9015e-05, 9.8936e-05, 9.8612e-05, 9.8035e-05, 9.7291e-05,\n",
      "         9.6858e-05, 9.6623e-05, 9.6437e-05, 9.6430e-05, 9.6186e-05, 9.5795e-05,\n",
      "         9.5658e-05, 9.5473e-05, 9.5460e-05, 9.4393e-05, 9.3583e-05, 9.3478e-05,\n",
      "         9.3187e-05, 9.3147e-05, 9.2899e-05, 9.2747e-05, 9.1598e-05, 9.1369e-05,\n",
      "         9.1163e-05, 9.1114e-05, 9.0927e-05, 9.0764e-05, 9.0760e-05, 9.0336e-05,\n",
      "         9.0294e-05, 9.0268e-05, 9.0170e-05, 9.0042e-05, 8.9998e-05, 8.9920e-05,\n",
      "         8.9604e-05, 8.9305e-05, 8.9125e-05, 8.8995e-05, 8.8804e-05, 8.8740e-05,\n",
      "         8.8649e-05, 8.8447e-05, 8.8194e-05, 8.8089e-05]]),\n",
      "indices=tensor([[ 948,  810, 2768,  604,  843, 1037, 1317,   71, 2307, 2304,  883, 2151,\n",
      "         2493, 3178, 1630, 2345,  809, 1223, 3129, 1730, 2865,  964, 1148, 2240,\n",
      "         1930,  906,  234, 2286, 2650, 1132,  928, 2935,    0, 2787, 1464, 1448,\n",
      "         1627, 3149, 2378, 1811, 1734, 2558, 1367,  781, 1326, 2111,  131, 2026,\n",
      "         1843,  334,  602, 3194, 1198, 1635,  482, 2377, 1920,  280, 2150, 2958,\n",
      "         3297,  148, 3216,  858, 1208, 3016, 2234,  684, 3280,  434,  561, 1993,\n",
      "         1151, 3126,  988,  254,  430,  829, 2844,  893, 2473,  410, 1679, 1916,\n",
      "          727, 2194, 3195, 2430,  565, 1795, 2953, 1043, 2847, 3182, 2121, 1064,\n",
      "         2352, 2656, 1790,   40]]))\n",
      "top_k_indices: [[948, 810, 2768, 604, 843, 1037, 1317, 71, 2307, 2304, 883, 2151, 2493, 3178, 1630, 2345, 809, 1223, 3129, 1730, 2865, 964, 1148, 2240, 1930, 906, 234, 2286, 2650, 1132, 928, 2935, 0, 2787, 1464, 1448, 1627, 3149, 2378, 1811, 1734, 2558, 1367, 781, 1326, 2111, 131, 2026, 1843, 334, 602, 3194, 1198, 1635, 482, 2377, 1920, 280, 2150, 2958, 3297, 148, 3216, 858, 1208, 3016, 2234, 684, 3280, 434, 561, 1993, 1151, 3126, 988, 254, 430, 829, 2844, 893, 2473, 410, 1679, 1916, 727, 2194, 3195, 2430, 565, 1795, 2953, 1043, 2847, 3182, 2121, 1064, 2352, 2656, 1790, 40]]\n",
      "top_k_names: ['RPL13A', 'RPL37A', 'HLA-A', 'ACTG1', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ITM2B', 'GPX3', 'RPL5', 'MYL6', 'RPL8', 'RPL15', 'ATP5F1A', 'LDHB', 'RPS16', 'TMBIM6', 'SELENOP', 'VIM', 'IGFBP7', 'RPL38', 'ATP5F1C', 'CAPN2', 'ATP5PO', 'SOD1', 'RTN4', 'CD63', 'SRP9', 'SUCLG1', 'CRYAB', 'HNRNPK', 'RHOA', 'ISCU', 'NACA4P', 'NDUFB2', 'GNAS', 'NOP53', 'ALDOB', 'S100A10', 'SEC61B', 'SPCS1', 'NDUFB1', 'AKR1A1', 'BHMT', 'RAC1', 'PTGES3', 'GHITM', 'ECH1', 'GABARAP', 'ACTB', 'ATP5F1B', 'ALDH2', 'NEDD8', 'A2M', 'ALDH9A1', 'DAD1', 'CCT8', 'COX8A', 'NDUFA1', 'AMOT', 'UMOD', 'KARS', 'GADD45A', 'PSMA6', 'MT1F', 'CLTA', 'ADI1', 'NDUFB3', 'MGP', 'ACADVL', 'GSTO1', 'RHOC', 'GATM', 'PSMB1', 'ATP5PF', 'HADHB', 'LTA4H', 'S100A6', 'PEPD', 'PSMB5', 'SARAF', 'SERINC1', 'YWHAZ', 'AGMAT', 'TPI1', 'TUBB2A', 'SDC4', 'ACAT1', 'PHB2', 'SGK1', 'TMEM147', 'HLA-DRA', 'TST', 'HSD17B12', 'PEBP1', 'ANXA7', 'EIF4G2', 'DAB2', 'CSRP1']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1'], ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'GPX3', 'MT1G', 'RPS24', 'ACTG1', 'ATP5F1A', 'MT2A', 'ITM2B', 'RPL5', 'LDHB', 'MYL6', 'RPS16', 'RPL8', 'RPL15', 'IGFBP7', 'SELENOP', 'CAPN2', 'RPL38', 'RTN4', 'CD63', 'ATP5F1C', 'TMBIM6', 'HNRNPK', 'VIM', 'CRYAB', 'SRP9', 'ATP5PO', 'SOD1', 'NOP53', 'ISCU', 'S100A10', 'GHITM', 'SUCLG1', 'ATP5F1B', 'NACA4P', 'RHOA', 'ALDOB', 'NDUFB1', 'GNAS', 'NDUFB2', 'ALDH2', 'SPCS1', 'SEC61B', 'NEDD8', 'AKR1A1', 'A2M', 'NDUFB3', 'ALDH9A1', 'ECH1', 'ACTB', 'BHMT', 'RAC1', 'GABARAP', 'MT1F', 'UMOD', 'ADI1', 'NDUFA1', 'CCT8', 'PTGES3', 'COX8A', 'AMOT', 'GATM', 'MGP', 'DAD1', 'GADD45A', 'KARS', 'ACADVL', 'ATP5PF', 'PSMB1', 'SARAF', 'PSMA6', 'CLTA', 'HADHB', 'HSD17B12', 'UQCR10', 'TST', 'PEBP1', 'GSTO1', 'PSMB5', 'TMEM147', 'SDC4', 'S100A6', 'LTA4H', 'PHB2', 'TPI1', 'ADH5', 'RHOC', 'COX5B', 'ALDOA', 'SERINC1', 'SLC38A2', 'TUBB2A', 'YPEL5', 'FOXC1', 'MRPL49', 'PEPD', 'AGMAT'], ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'MT2A', 'ACTG1', 'RPS24', 'GPX3', 'ITM2B', 'RPL8', 'MYL6', 'ATP5F1A', 'RPL5', 'LDHB', 'RPL15', 'SELENOP', 'RPS16', 'TMBIM6', 'RPL38', 'ATP5F1C', 'CD63', 'ATP5PO', 'RTN4', 'VIM', 'IGFBP7', 'CAPN2', 'ISCU', 'SOD1', 'SRP9', 'HNRNPK', 'SUCLG1', 'CRYAB', 'ALDOB', 'S100A10', 'NDUFB2', 'NOP53', 'GNAS', 'RHOA', 'SPCS1', 'ALDH2', 'AKR1A1', 'GABARAP', 'BHMT', 'NEDD8', 'NDUFB1', 'SEC61B', 'ATP5F1B', 'ECH1', 'NACA4P', 'PTGES3', 'RAC1', 'GHITM', 'ACTB', 'ALDH9A1', 'COX8A', 'A2M', 'CCT8', 'NDUFA1', 'GATM', 'UMOD', 'NDUFB3', 'KARS', 'MGP', 'PSMA6', 'CLTA', 'AMOT', 'ADI1', 'GADD45A', 'DAD1', 'MT1F', 'RHOC', 'ACADVL', 'PSMB1', 'ATP5PF', 'SERINC1', 'SARAF', 'GSTO1', 'TST', 'HSD17B12', 'LTA4H', 'HADHB', 'PEPD', 'PSMB5', 'AGMAT', 'YWHAZ', 'SGK1', 'TPI1', 'TUBB2A', 'S100A6', 'TMEM147', 'TMED9', 'ACAT1', 'EIF4G2', 'MRPL49', 'PHYH', 'PHB2', 'CAPNS1', 'ANXA7', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'ACTG1', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ITM2B', 'GPX3', 'RPL5', 'MYL6', 'RPL8', 'RPL15', 'ATP5F1A', 'LDHB', 'RPS16', 'TMBIM6', 'SELENOP', 'VIM', 'IGFBP7', 'RPL38', 'ATP5F1C', 'CAPN2', 'ATP5PO', 'SOD1', 'RTN4', 'CD63', 'SRP9', 'SUCLG1', 'CRYAB', 'HNRNPK', 'RHOA', 'ISCU', 'NACA4P', 'NDUFB2', 'GNAS', 'NOP53', 'ALDOB', 'S100A10', 'SEC61B', 'SPCS1', 'NDUFB1', 'AKR1A1', 'BHMT', 'RAC1', 'PTGES3', 'GHITM', 'ECH1', 'GABARAP', 'ACTB', 'ATP5F1B', 'ALDH2', 'NEDD8', 'A2M', 'ALDH9A1', 'DAD1', 'CCT8', 'COX8A', 'NDUFA1', 'AMOT', 'UMOD', 'KARS', 'GADD45A', 'PSMA6', 'MT1F', 'CLTA', 'ADI1', 'NDUFB3', 'MGP', 'ACADVL', 'GSTO1', 'RHOC', 'GATM', 'PSMB1', 'ATP5PF', 'HADHB', 'LTA4H', 'S100A6', 'PEPD', 'PSMB5', 'SARAF', 'SERINC1', 'YWHAZ', 'AGMAT', 'TPI1', 'TUBB2A', 'SDC4', 'ACAT1', 'PHB2', 'SGK1', 'TMEM147', 'HLA-DRA', 'TST', 'HSD17B12', 'PEBP1', 'ANXA7', 'EIF4G2', 'DAB2', 'CSRP1']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1300, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.3691e-04, 1.3501e-04, 1.3165e-04, 1.2643e-04, 1.2328e-04, 1.2318e-04,\n",
      "         1.2189e-04, 1.2154e-04, 1.2133e-04, 1.1960e-04, 1.1754e-04, 1.1728e-04,\n",
      "         1.1660e-04, 1.1589e-04, 1.1481e-04, 1.1394e-04, 1.1328e-04, 1.1144e-04,\n",
      "         1.1023e-04, 1.0961e-04, 1.0687e-04, 1.0653e-04, 1.0643e-04, 1.0516e-04,\n",
      "         1.0502e-04, 1.0459e-04, 1.0444e-04, 1.0364e-04, 1.0351e-04, 1.0262e-04,\n",
      "         1.0228e-04, 1.0142e-04, 1.0115e-04, 1.0105e-04, 1.0089e-04, 1.0057e-04,\n",
      "         9.9500e-05, 9.9316e-05, 9.9078e-05, 9.8625e-05, 9.8539e-05, 9.8470e-05,\n",
      "         9.7898e-05, 9.7499e-05, 9.7237e-05, 9.7155e-05, 9.6980e-05, 9.6795e-05,\n",
      "         9.6481e-05, 9.6455e-05, 9.5656e-05, 9.5434e-05, 9.5304e-05, 9.5184e-05,\n",
      "         9.4868e-05, 9.4841e-05, 9.4712e-05, 9.4504e-05, 9.4294e-05, 9.4245e-05,\n",
      "         9.3412e-05, 9.2741e-05, 9.2003e-05, 9.1907e-05, 9.0674e-05, 9.0651e-05,\n",
      "         9.0022e-05, 8.9732e-05, 8.9355e-05, 8.9240e-05, 8.9216e-05, 8.9111e-05,\n",
      "         8.8295e-05, 8.8087e-05, 8.7324e-05, 8.7119e-05, 8.7018e-05, 8.6878e-05,\n",
      "         8.6704e-05, 8.6685e-05, 8.6579e-05, 8.6493e-05, 8.6431e-05, 8.6387e-05,\n",
      "         8.5976e-05, 8.5831e-05, 8.5721e-05, 8.5702e-05, 8.5098e-05, 8.4959e-05,\n",
      "         8.4937e-05, 8.4633e-05, 8.4596e-05, 8.4500e-05, 8.4329e-05, 8.4134e-05,\n",
      "         8.3615e-05, 8.3513e-05, 8.3447e-05, 8.3360e-05]]),\n",
      "indices=tensor([[ 948,  810, 2768,  843, 1037, 1317,   71, 2304,  604,  883, 1630, 2307,\n",
      "         2151, 2345,  809, 3178, 2493, 2865,  964, 3129,  234, 2240, 1148, 1730,\n",
      "         2787, 2935, 2286, 1930, 1223,  928, 2650,  906, 1367, 3149, 3194, 1132,\n",
      "         2026, 1448, 1464, 2378, 1198, 1627, 1811,    0,  482, 2111, 2558,  781,\n",
      "         1326, 1734,  334, 3016, 2150, 3280, 2958,  131, 1843,  602,  684, 1635,\n",
      "          148, 2377,  858,  280, 3297, 1920,  434, 3216,  561, 3126, 2234, 1208,\n",
      "          254,  430,  988, 1043, 1064, 1151,  893, 2844, 2194,  829,  410, 1993,\n",
      "         3268, 2121, 2235, 2430, 2130, 1679, 3182,  920, 1795, 2953, 2473, 1574,\n",
      "         2775,   40,  327, 2159]]))\n",
      "top_k_indices: [[948, 810, 2768, 843, 1037, 1317, 71, 2304, 604, 883, 1630, 2307, 2151, 2345, 809, 3178, 2493, 2865, 964, 3129, 234, 2240, 1148, 1730, 2787, 2935, 2286, 1930, 1223, 928, 2650, 906, 1367, 3149, 3194, 1132, 2026, 1448, 1464, 2378, 1198, 1627, 1811, 0, 482, 2111, 2558, 781, 1326, 1734, 334, 3016, 2150, 3280, 2958, 131, 1843, 602, 684, 1635, 148, 2377, 858, 280, 3297, 1920, 434, 3216, 561, 3126, 2234, 1208, 254, 430, 988, 1043, 1064, 1151, 893, 2844, 2194, 829, 410, 1993, 3268, 2121, 2235, 2430, 2130, 1679, 3182, 920, 1795, 2953, 2473, 1574, 2775, 40, 327, 2159]]\n",
      "top_k_names: ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'GPX3', 'ACTG1', 'RPL5', 'ATP5F1A', 'ITM2B', 'MYL6', 'LDHB', 'RPS16', 'RPL15', 'RPL8', 'IGFBP7', 'RPL38', 'SELENOP', 'RTN4', 'CAPN2', 'ATP5F1C', 'VIM', 'ISCU', 'HNRNPK', 'CD63', 'ATP5PO', 'TMBIM6', 'CRYAB', 'SRP9', 'SOD1', 'NDUFB1', 'NOP53', 'ATP5F1B', 'SUCLG1', 'GHITM', 'NDUFB2', 'NACA4P', 'ALDOB', 'ALDH2', 'GNAS', 'S100A10', 'RHOA', 'A2M', 'RAC1', 'SPCS1', 'AKR1A1', 'BHMT', 'SEC61B', 'GABARAP', 'MT1F', 'COX8A', 'NDUFB3', 'NDUFA1', 'PTGES3', 'ECH1', 'ACTB', 'ADI1', 'NEDD8', 'UMOD', 'ALDH9A1', 'GADD45A', 'CCT8', 'AMOT', 'DAD1', 'MGP', 'KARS', 'ACADVL', 'GATM', 'CLTA', 'PSMA6', 'ATP5PF', 'HADHB', 'PSMB1', 'TMEM147', 'PEBP1', 'RHOC', 'PEPD', 'S100A6', 'TPI1', 'LTA4H', 'SARAF', 'GSTO1', 'UQCR10', 'HSD17B12', 'MRPL49', 'SDC4', 'SLC38A2', 'SERINC1', 'TST', 'ATOX1', 'PHB2', 'SGK1', 'PSMB5', 'COX5B', 'FOXC1', 'CSRP1', 'PAM', 'CAPNS1']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1'], ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'GPX3', 'MT1G', 'RPS24', 'ACTG1', 'ATP5F1A', 'MT2A', 'ITM2B', 'RPL5', 'LDHB', 'MYL6', 'RPS16', 'RPL8', 'RPL15', 'IGFBP7', 'SELENOP', 'CAPN2', 'RPL38', 'RTN4', 'CD63', 'ATP5F1C', 'TMBIM6', 'HNRNPK', 'VIM', 'CRYAB', 'SRP9', 'ATP5PO', 'SOD1', 'NOP53', 'ISCU', 'S100A10', 'GHITM', 'SUCLG1', 'ATP5F1B', 'NACA4P', 'RHOA', 'ALDOB', 'NDUFB1', 'GNAS', 'NDUFB2', 'ALDH2', 'SPCS1', 'SEC61B', 'NEDD8', 'AKR1A1', 'A2M', 'NDUFB3', 'ALDH9A1', 'ECH1', 'ACTB', 'BHMT', 'RAC1', 'GABARAP', 'MT1F', 'UMOD', 'ADI1', 'NDUFA1', 'CCT8', 'PTGES3', 'COX8A', 'AMOT', 'GATM', 'MGP', 'DAD1', 'GADD45A', 'KARS', 'ACADVL', 'ATP5PF', 'PSMB1', 'SARAF', 'PSMA6', 'CLTA', 'HADHB', 'HSD17B12', 'UQCR10', 'TST', 'PEBP1', 'GSTO1', 'PSMB5', 'TMEM147', 'SDC4', 'S100A6', 'LTA4H', 'PHB2', 'TPI1', 'ADH5', 'RHOC', 'COX5B', 'ALDOA', 'SERINC1', 'SLC38A2', 'TUBB2A', 'YPEL5', 'FOXC1', 'MRPL49', 'PEPD', 'AGMAT'], ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'MT2A', 'ACTG1', 'RPS24', 'GPX3', 'ITM2B', 'RPL8', 'MYL6', 'ATP5F1A', 'RPL5', 'LDHB', 'RPL15', 'SELENOP', 'RPS16', 'TMBIM6', 'RPL38', 'ATP5F1C', 'CD63', 'ATP5PO', 'RTN4', 'VIM', 'IGFBP7', 'CAPN2', 'ISCU', 'SOD1', 'SRP9', 'HNRNPK', 'SUCLG1', 'CRYAB', 'ALDOB', 'S100A10', 'NDUFB2', 'NOP53', 'GNAS', 'RHOA', 'SPCS1', 'ALDH2', 'AKR1A1', 'GABARAP', 'BHMT', 'NEDD8', 'NDUFB1', 'SEC61B', 'ATP5F1B', 'ECH1', 'NACA4P', 'PTGES3', 'RAC1', 'GHITM', 'ACTB', 'ALDH9A1', 'COX8A', 'A2M', 'CCT8', 'NDUFA1', 'GATM', 'UMOD', 'NDUFB3', 'KARS', 'MGP', 'PSMA6', 'CLTA', 'AMOT', 'ADI1', 'GADD45A', 'DAD1', 'MT1F', 'RHOC', 'ACADVL', 'PSMB1', 'ATP5PF', 'SERINC1', 'SARAF', 'GSTO1', 'TST', 'HSD17B12', 'LTA4H', 'HADHB', 'PEPD', 'PSMB5', 'AGMAT', 'YWHAZ', 'SGK1', 'TPI1', 'TUBB2A', 'S100A6', 'TMEM147', 'TMED9', 'ACAT1', 'EIF4G2', 'MRPL49', 'PHYH', 'PHB2', 'CAPNS1', 'ANXA7', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'ACTG1', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ITM2B', 'GPX3', 'RPL5', 'MYL6', 'RPL8', 'RPL15', 'ATP5F1A', 'LDHB', 'RPS16', 'TMBIM6', 'SELENOP', 'VIM', 'IGFBP7', 'RPL38', 'ATP5F1C', 'CAPN2', 'ATP5PO', 'SOD1', 'RTN4', 'CD63', 'SRP9', 'SUCLG1', 'CRYAB', 'HNRNPK', 'RHOA', 'ISCU', 'NACA4P', 'NDUFB2', 'GNAS', 'NOP53', 'ALDOB', 'S100A10', 'SEC61B', 'SPCS1', 'NDUFB1', 'AKR1A1', 'BHMT', 'RAC1', 'PTGES3', 'GHITM', 'ECH1', 'GABARAP', 'ACTB', 'ATP5F1B', 'ALDH2', 'NEDD8', 'A2M', 'ALDH9A1', 'DAD1', 'CCT8', 'COX8A', 'NDUFA1', 'AMOT', 'UMOD', 'KARS', 'GADD45A', 'PSMA6', 'MT1F', 'CLTA', 'ADI1', 'NDUFB3', 'MGP', 'ACADVL', 'GSTO1', 'RHOC', 'GATM', 'PSMB1', 'ATP5PF', 'HADHB', 'LTA4H', 'S100A6', 'PEPD', 'PSMB5', 'SARAF', 'SERINC1', 'YWHAZ', 'AGMAT', 'TPI1', 'TUBB2A', 'SDC4', 'ACAT1', 'PHB2', 'SGK1', 'TMEM147', 'HLA-DRA', 'TST', 'HSD17B12', 'PEBP1', 'ANXA7', 'EIF4G2', 'DAB2', 'CSRP1'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'GPX3', 'ACTG1', 'RPL5', 'ATP5F1A', 'ITM2B', 'MYL6', 'LDHB', 'RPS16', 'RPL15', 'RPL8', 'IGFBP7', 'RPL38', 'SELENOP', 'RTN4', 'CAPN2', 'ATP5F1C', 'VIM', 'ISCU', 'HNRNPK', 'CD63', 'ATP5PO', 'TMBIM6', 'CRYAB', 'SRP9', 'SOD1', 'NDUFB1', 'NOP53', 'ATP5F1B', 'SUCLG1', 'GHITM', 'NDUFB2', 'NACA4P', 'ALDOB', 'ALDH2', 'GNAS', 'S100A10', 'RHOA', 'A2M', 'RAC1', 'SPCS1', 'AKR1A1', 'BHMT', 'SEC61B', 'GABARAP', 'MT1F', 'COX8A', 'NDUFB3', 'NDUFA1', 'PTGES3', 'ECH1', 'ACTB', 'ADI1', 'NEDD8', 'UMOD', 'ALDH9A1', 'GADD45A', 'CCT8', 'AMOT', 'DAD1', 'MGP', 'KARS', 'ACADVL', 'GATM', 'CLTA', 'PSMA6', 'ATP5PF', 'HADHB', 'PSMB1', 'TMEM147', 'PEBP1', 'RHOC', 'PEPD', 'S100A6', 'TPI1', 'LTA4H', 'SARAF', 'GSTO1', 'UQCR10', 'HSD17B12', 'MRPL49', 'SDC4', 'SLC38A2', 'SERINC1', 'TST', 'ATOX1', 'PHB2', 'SGK1', 'PSMB5', 'COX5B', 'FOXC1', 'CSRP1', 'PAM', 'CAPNS1']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.0000, 0.1464, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.5603e-04, 1.4945e-04, 1.4555e-04, 1.4457e-04, 1.4293e-04, 1.4110e-04,\n",
      "         1.3930e-04, 1.3654e-04, 1.3566e-04, 1.3426e-04, 1.3334e-04, 1.3215e-04,\n",
      "         1.3205e-04, 1.3202e-04, 1.3081e-04, 1.2907e-04, 1.2664e-04, 1.2561e-04,\n",
      "         1.2441e-04, 1.2207e-04, 1.2162e-04, 1.2079e-04, 1.2029e-04, 1.1900e-04,\n",
      "         1.1840e-04, 1.1835e-04, 1.1831e-04, 1.1821e-04, 1.1758e-04, 1.1691e-04,\n",
      "         1.1548e-04, 1.1418e-04, 1.1389e-04, 1.1356e-04, 1.1343e-04, 1.1296e-04,\n",
      "         1.1163e-04, 1.1132e-04, 1.1113e-04, 1.1108e-04, 1.1028e-04, 1.1001e-04,\n",
      "         1.0989e-04, 1.0980e-04, 1.0918e-04, 1.0868e-04, 1.0848e-04, 1.0806e-04,\n",
      "         1.0806e-04, 1.0725e-04, 1.0709e-04, 1.0706e-04, 1.0694e-04, 1.0636e-04,\n",
      "         1.0630e-04, 1.0619e-04, 1.0603e-04, 1.0580e-04, 1.0503e-04, 1.0479e-04,\n",
      "         1.0470e-04, 1.0467e-04, 1.0460e-04, 1.0404e-04, 1.0396e-04, 1.0394e-04,\n",
      "         1.0336e-04, 1.0301e-04, 1.0175e-04, 1.0172e-04, 1.0119e-04, 1.0108e-04,\n",
      "         1.0085e-04, 1.0068e-04, 1.0051e-04, 9.9807e-05, 9.9519e-05, 9.9289e-05,\n",
      "         9.9152e-05, 9.8522e-05, 9.7809e-05, 9.7386e-05, 9.7318e-05, 9.7244e-05,\n",
      "         9.7022e-05, 9.6868e-05, 9.6063e-05, 9.5920e-05, 9.5849e-05, 9.5714e-05,\n",
      "         9.5657e-05, 9.5603e-05, 9.5595e-05, 9.5483e-05, 9.5243e-05, 9.5218e-05,\n",
      "         9.4887e-05, 9.4584e-05, 9.4538e-05, 9.4413e-05]]),\n",
      "indices=tensor([[ 810,  948,  843, 2768, 1037, 2304, 1317,  604,  883, 2307,   71, 2151,\n",
      "         1630, 2345, 2493, 3178, 3129,  809,  964, 1148,  234, 2286, 2865, 2240,\n",
      "         2935, 2650, 2787,  928, 1223, 1730, 1930,  906, 2378, 1132, 3149, 1811,\n",
      "         1367, 3194, 2026, 1627, 1198,    0, 1464, 1448, 2558,  781, 1635,  334,\n",
      "         1734, 1326,  602, 2958, 3280,  131, 2377,  482, 1843, 2111, 3126,  148,\n",
      "         2150,  280, 3016,  858, 3216,  684, 3297,  434, 2234,  254,  410,  561,\n",
      "          988, 1208, 1920, 3182, 2121, 1151, 1993, 1679,  430,  893, 1043, 2235,\n",
      "         2844,  829, 2194, 3268, 2473, 2775, 1020, 2656, 1064,  727, 3195, 1325,\n",
      "         2953, 1795, 2130, 1983]]))\n",
      "top_k_indices: [[810, 948, 843, 2768, 1037, 2304, 1317, 604, 883, 2307, 71, 2151, 1630, 2345, 2493, 3178, 3129, 809, 964, 1148, 234, 2286, 2865, 2240, 2935, 2650, 2787, 928, 1223, 1730, 1930, 906, 2378, 1132, 3149, 1811, 1367, 3194, 2026, 1627, 1198, 0, 1464, 1448, 2558, 781, 1635, 334, 1734, 1326, 602, 2958, 3280, 131, 2377, 482, 1843, 2111, 3126, 148, 2150, 280, 3016, 858, 3216, 684, 3297, 434, 2234, 254, 410, 561, 988, 1208, 1920, 3182, 2121, 1151, 1993, 1679, 430, 893, 1043, 2235, 2844, 829, 2194, 3268, 2473, 2775, 1020, 2656, 1064, 727, 3195, 1325, 2953, 1795, 2130, 1983]]\n",
      "top_k_names: ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'GPX3', 'MT2A', 'ACTG1', 'RPL5', 'ITM2B', 'RPS24', 'MYL6', 'ATP5F1A', 'LDHB', 'RPL8', 'RPL15', 'SELENOP', 'RPS16', 'RPL38', 'ATP5F1C', 'RTN4', 'CD63', 'IGFBP7', 'CAPN2', 'HNRNPK', 'SRP9', 'ISCU', 'CRYAB', 'TMBIM6', 'VIM', 'ATP5PO', 'SOD1', 'ALDOB', 'SUCLG1', 'NOP53', 'S100A10', 'NDUFB1', 'ATP5F1B', 'GHITM', 'GNAS', 'ALDH2', 'RHOA', 'NACA4P', 'NDUFB2', 'SPCS1', 'AKR1A1', 'NEDD8', 'GABARAP', 'SEC61B', 'BHMT', 'ACTB', 'NDUFA1', 'NDUFB3', 'PTGES3', 'ALDH9A1', 'A2M', 'ECH1', 'RAC1', 'GATM', 'UMOD', 'COX8A', 'CCT8', 'MT1F', 'GADD45A', 'KARS', 'ADI1', 'AMOT', 'MGP', 'CLTA', 'ATP5PF', 'SARAF', 'ACADVL', 'PSMB1', 'PSMA6', 'DAD1', 'TST', 'HSD17B12', 'RHOC', 'GSTO1', 'SERINC1', 'HADHB', 'PEPD', 'TMEM147', 'MRPL49', 'S100A6', 'LTA4H', 'TPI1', 'UQCR10', 'PSMB5', 'FOXC1', 'TMED9', 'EIF4G2', 'PEBP1', 'AGMAT', 'TUBB2A', 'ALDOA', 'SGK1', 'PHB2', 'SLC38A2', 'PHYH']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1'], ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'GPX3', 'MT1G', 'RPS24', 'ACTG1', 'ATP5F1A', 'MT2A', 'ITM2B', 'RPL5', 'LDHB', 'MYL6', 'RPS16', 'RPL8', 'RPL15', 'IGFBP7', 'SELENOP', 'CAPN2', 'RPL38', 'RTN4', 'CD63', 'ATP5F1C', 'TMBIM6', 'HNRNPK', 'VIM', 'CRYAB', 'SRP9', 'ATP5PO', 'SOD1', 'NOP53', 'ISCU', 'S100A10', 'GHITM', 'SUCLG1', 'ATP5F1B', 'NACA4P', 'RHOA', 'ALDOB', 'NDUFB1', 'GNAS', 'NDUFB2', 'ALDH2', 'SPCS1', 'SEC61B', 'NEDD8', 'AKR1A1', 'A2M', 'NDUFB3', 'ALDH9A1', 'ECH1', 'ACTB', 'BHMT', 'RAC1', 'GABARAP', 'MT1F', 'UMOD', 'ADI1', 'NDUFA1', 'CCT8', 'PTGES3', 'COX8A', 'AMOT', 'GATM', 'MGP', 'DAD1', 'GADD45A', 'KARS', 'ACADVL', 'ATP5PF', 'PSMB1', 'SARAF', 'PSMA6', 'CLTA', 'HADHB', 'HSD17B12', 'UQCR10', 'TST', 'PEBP1', 'GSTO1', 'PSMB5', 'TMEM147', 'SDC4', 'S100A6', 'LTA4H', 'PHB2', 'TPI1', 'ADH5', 'RHOC', 'COX5B', 'ALDOA', 'SERINC1', 'SLC38A2', 'TUBB2A', 'YPEL5', 'FOXC1', 'MRPL49', 'PEPD', 'AGMAT'], ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'MT2A', 'ACTG1', 'RPS24', 'GPX3', 'ITM2B', 'RPL8', 'MYL6', 'ATP5F1A', 'RPL5', 'LDHB', 'RPL15', 'SELENOP', 'RPS16', 'TMBIM6', 'RPL38', 'ATP5F1C', 'CD63', 'ATP5PO', 'RTN4', 'VIM', 'IGFBP7', 'CAPN2', 'ISCU', 'SOD1', 'SRP9', 'HNRNPK', 'SUCLG1', 'CRYAB', 'ALDOB', 'S100A10', 'NDUFB2', 'NOP53', 'GNAS', 'RHOA', 'SPCS1', 'ALDH2', 'AKR1A1', 'GABARAP', 'BHMT', 'NEDD8', 'NDUFB1', 'SEC61B', 'ATP5F1B', 'ECH1', 'NACA4P', 'PTGES3', 'RAC1', 'GHITM', 'ACTB', 'ALDH9A1', 'COX8A', 'A2M', 'CCT8', 'NDUFA1', 'GATM', 'UMOD', 'NDUFB3', 'KARS', 'MGP', 'PSMA6', 'CLTA', 'AMOT', 'ADI1', 'GADD45A', 'DAD1', 'MT1F', 'RHOC', 'ACADVL', 'PSMB1', 'ATP5PF', 'SERINC1', 'SARAF', 'GSTO1', 'TST', 'HSD17B12', 'LTA4H', 'HADHB', 'PEPD', 'PSMB5', 'AGMAT', 'YWHAZ', 'SGK1', 'TPI1', 'TUBB2A', 'S100A6', 'TMEM147', 'TMED9', 'ACAT1', 'EIF4G2', 'MRPL49', 'PHYH', 'PHB2', 'CAPNS1', 'ANXA7', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'ACTG1', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ITM2B', 'GPX3', 'RPL5', 'MYL6', 'RPL8', 'RPL15', 'ATP5F1A', 'LDHB', 'RPS16', 'TMBIM6', 'SELENOP', 'VIM', 'IGFBP7', 'RPL38', 'ATP5F1C', 'CAPN2', 'ATP5PO', 'SOD1', 'RTN4', 'CD63', 'SRP9', 'SUCLG1', 'CRYAB', 'HNRNPK', 'RHOA', 'ISCU', 'NACA4P', 'NDUFB2', 'GNAS', 'NOP53', 'ALDOB', 'S100A10', 'SEC61B', 'SPCS1', 'NDUFB1', 'AKR1A1', 'BHMT', 'RAC1', 'PTGES3', 'GHITM', 'ECH1', 'GABARAP', 'ACTB', 'ATP5F1B', 'ALDH2', 'NEDD8', 'A2M', 'ALDH9A1', 'DAD1', 'CCT8', 'COX8A', 'NDUFA1', 'AMOT', 'UMOD', 'KARS', 'GADD45A', 'PSMA6', 'MT1F', 'CLTA', 'ADI1', 'NDUFB3', 'MGP', 'ACADVL', 'GSTO1', 'RHOC', 'GATM', 'PSMB1', 'ATP5PF', 'HADHB', 'LTA4H', 'S100A6', 'PEPD', 'PSMB5', 'SARAF', 'SERINC1', 'YWHAZ', 'AGMAT', 'TPI1', 'TUBB2A', 'SDC4', 'ACAT1', 'PHB2', 'SGK1', 'TMEM147', 'HLA-DRA', 'TST', 'HSD17B12', 'PEBP1', 'ANXA7', 'EIF4G2', 'DAB2', 'CSRP1'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'GPX3', 'ACTG1', 'RPL5', 'ATP5F1A', 'ITM2B', 'MYL6', 'LDHB', 'RPS16', 'RPL15', 'RPL8', 'IGFBP7', 'RPL38', 'SELENOP', 'RTN4', 'CAPN2', 'ATP5F1C', 'VIM', 'ISCU', 'HNRNPK', 'CD63', 'ATP5PO', 'TMBIM6', 'CRYAB', 'SRP9', 'SOD1', 'NDUFB1', 'NOP53', 'ATP5F1B', 'SUCLG1', 'GHITM', 'NDUFB2', 'NACA4P', 'ALDOB', 'ALDH2', 'GNAS', 'S100A10', 'RHOA', 'A2M', 'RAC1', 'SPCS1', 'AKR1A1', 'BHMT', 'SEC61B', 'GABARAP', 'MT1F', 'COX8A', 'NDUFB3', 'NDUFA1', 'PTGES3', 'ECH1', 'ACTB', 'ADI1', 'NEDD8', 'UMOD', 'ALDH9A1', 'GADD45A', 'CCT8', 'AMOT', 'DAD1', 'MGP', 'KARS', 'ACADVL', 'GATM', 'CLTA', 'PSMA6', 'ATP5PF', 'HADHB', 'PSMB1', 'TMEM147', 'PEBP1', 'RHOC', 'PEPD', 'S100A6', 'TPI1', 'LTA4H', 'SARAF', 'GSTO1', 'UQCR10', 'HSD17B12', 'MRPL49', 'SDC4', 'SLC38A2', 'SERINC1', 'TST', 'ATOX1', 'PHB2', 'SGK1', 'PSMB5', 'COX5B', 'FOXC1', 'CSRP1', 'PAM', 'CAPNS1'], ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'GPX3', 'MT2A', 'ACTG1', 'RPL5', 'ITM2B', 'RPS24', 'MYL6', 'ATP5F1A', 'LDHB', 'RPL8', 'RPL15', 'SELENOP', 'RPS16', 'RPL38', 'ATP5F1C', 'RTN4', 'CD63', 'IGFBP7', 'CAPN2', 'HNRNPK', 'SRP9', 'ISCU', 'CRYAB', 'TMBIM6', 'VIM', 'ATP5PO', 'SOD1', 'ALDOB', 'SUCLG1', 'NOP53', 'S100A10', 'NDUFB1', 'ATP5F1B', 'GHITM', 'GNAS', 'ALDH2', 'RHOA', 'NACA4P', 'NDUFB2', 'SPCS1', 'AKR1A1', 'NEDD8', 'GABARAP', 'SEC61B', 'BHMT', 'ACTB', 'NDUFA1', 'NDUFB3', 'PTGES3', 'ALDH9A1', 'A2M', 'ECH1', 'RAC1', 'GATM', 'UMOD', 'COX8A', 'CCT8', 'MT1F', 'GADD45A', 'KARS', 'ADI1', 'AMOT', 'MGP', 'CLTA', 'ATP5PF', 'SARAF', 'ACADVL', 'PSMB1', 'PSMA6', 'DAD1', 'TST', 'HSD17B12', 'RHOC', 'GSTO1', 'SERINC1', 'HADHB', 'PEPD', 'TMEM147', 'MRPL49', 'S100A6', 'LTA4H', 'TPI1', 'UQCR10', 'PSMB5', 'FOXC1', 'TMED9', 'EIF4G2', 'PEBP1', 'AGMAT', 'TUBB2A', 'ALDOA', 'SGK1', 'PHB2', 'SLC38A2', 'PHYH']]\n",
      "x: torch.Size([1, 3300])\n",
      "rel_for_clas=None: tensor([[0.1578, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001]]),\n",
      "indices=tensor([[ 810,  948,  843, 1037, 2768, 2304, 1317,  604,  883, 2307, 2151, 2345,\n",
      "           71, 2493, 1630, 3178, 3129,  964,  809, 1148,  234, 2286, 2787, 2935,\n",
      "         1223, 2650,  928, 2240, 1730, 2865, 1930,  906, 2378, 1132, 3149, 1811,\n",
      "         1367, 1627, 1198, 3194, 1464, 2558, 2026,    0,  334, 1448, 1635,  781,\n",
      "         1734, 1326,  131,  602, 2958, 3280,  482, 1843, 3126, 2377,  280, 2111,\n",
      "         3216, 2150,  858,  148, 3297, 3016,  434,  684, 2234,  254, 1208,  410,\n",
      "          988,  561, 1920, 3182, 1993, 1151, 2121, 1679,  893, 2235,  430,  829,\n",
      "         1043, 1020, 2844,  727, 2656, 3195, 2473, 2775, 2194, 2953, 3268, 1325,\n",
      "         1354, 1983, 2610,  565]]))\n",
      "top_k_indices: [[810, 948, 843, 1037, 2768, 2304, 1317, 604, 883, 2307, 2151, 2345, 71, 2493, 1630, 3178, 3129, 964, 809, 1148, 234, 2286, 2787, 2935, 1223, 2650, 928, 2240, 1730, 2865, 1930, 906, 2378, 1132, 3149, 1811, 1367, 1627, 1198, 3194, 1464, 2558, 2026, 0, 334, 1448, 1635, 781, 1734, 1326, 131, 602, 2958, 3280, 482, 1843, 3126, 2377, 280, 2111, 3216, 2150, 858, 148, 3297, 3016, 434, 684, 2234, 254, 1208, 410, 988, 561, 1920, 3182, 1993, 1151, 2121, 1679, 893, 2235, 430, 829, 1043, 1020, 2844, 727, 2656, 3195, 2473, 2775, 2194, 2953, 3268, 1325, 1354, 1983, 2610, 565]]\n",
      "top_k_names: ['RPL37A', 'RPL13A', 'UBB', 'MT1G', 'HLA-A', 'GPX3', 'MT2A', 'ACTG1', 'RPL5', 'ITM2B', 'MYL6', 'LDHB', 'RPS24', 'RPL8', 'ATP5F1A', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'RTN4', 'CD63', 'ISCU', 'HNRNPK', 'TMBIM6', 'SRP9', 'CRYAB', 'CAPN2', 'VIM', 'IGFBP7', 'ATP5PO', 'SOD1', 'ALDOB', 'SUCLG1', 'NOP53', 'S100A10', 'NDUFB1', 'GNAS', 'ALDH2', 'ATP5F1B', 'NACA4P', 'SPCS1', 'GHITM', 'RHOA', 'GABARAP', 'NDUFB2', 'NEDD8', 'AKR1A1', 'SEC61B', 'BHMT', 'PTGES3', 'ACTB', 'NDUFA1', 'NDUFB3', 'A2M', 'ECH1', 'GATM', 'ALDH9A1', 'CCT8', 'RAC1', 'KARS', 'COX8A', 'GADD45A', 'UMOD', 'AMOT', 'MT1F', 'MGP', 'ADI1', 'CLTA', 'ATP5PF', 'PSMA6', 'SARAF', 'PSMB1', 'ACADVL', 'DAD1', 'TST', 'GSTO1', 'RHOC', 'HSD17B12', 'SERINC1', 'PEPD', 'MRPL49', 'HADHB', 'LTA4H', 'TMEM147', 'TMED9', 'S100A6', 'AGMAT', 'EIF4G2', 'TUBB2A', 'PSMB5', 'FOXC1', 'TPI1', 'SGK1', 'UQCR10', 'ALDOA', 'H2AFZ', 'PHYH', 'SSR4', 'ACAT1']\n",
      "contri_k_names: [['RPL37A', 'RPL13A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ACTG1', 'ITM2B', 'ATP5F1A', 'GPX3', 'MYL6', 'RPS16', 'RPL8', 'RPL5', 'RPL15', 'LDHB', 'SELENOP', 'IGFBP7', 'RPL38', 'ATP5F1C', 'RTN4', 'ATP5PO', 'ISCU', 'CD63', 'TMBIM6', 'CAPN2', 'VIM', 'HNRNPK', 'SUCLG1', 'SOD1', 'SRP9', 'NOP53', 'GABARAP', 'GNAS', 'RHOA', 'NDUFB2', 'ALDH2', 'CRYAB', 'SEC61B', 'ALDOB', 'NACA4P', 'ATP5F1B', 'SPCS1', 'S100A10', 'PTGES3', 'NDUFB1', 'BHMT', 'RAC1', 'AKR1A1', 'GHITM', 'ECH1', 'NEDD8', 'ACTB', 'NDUFB3', 'COX8A', 'A2M', 'UMOD', 'ADI1', 'NDUFA1', 'MGP', 'GADD45A', 'CCT8', 'MT1F', 'ALDH9A1', 'PSMA6', 'KARS', 'DAD1', 'GATM', 'AMOT', 'CLTA', 'ACADVL', 'GSTO1', 'ATP5PF', 'PSMB1', 'LTA4H', 'RHOC', 'TST', 'TPI1', 'SERINC1', 'PEBP1', 'SARAF', 'YWHAZ', 'TMEM147', 'HSD17B12', 'HADHB', 'PSMB5', 'PEPD', 'AGMAT', 'S100A6', 'COX5B', 'SLC38A2', 'SDC4', 'CAPNS1', 'PHB2', 'SGK1', 'UQCR10', 'PSME1', 'ADH5', 'CSRP1'], ['RPL37A', 'RPL13A', 'MT1G', 'UBB', 'HLA-A', 'MT2A', 'ACTG1', 'GPX3', 'ITM2B', 'RPL5', 'RPS24', 'ATP5F1A', 'RPL8', 'MYL6', 'LDHB', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'VIM', 'SRP9', 'ATP5PO', 'CAPN2', 'IGFBP7', 'CRYAB', 'HNRNPK', 'ISCU', 'SOD1', 'ALDOB', 'SUCLG1', 'S100A10', 'GNAS', 'NOP53', 'NDUFB2', 'NDUFB1', 'RHOA', 'ALDH2', 'AKR1A1', 'SPCS1', 'NEDD8', 'BHMT', 'ATP5F1B', 'RAC1', 'GABARAP', 'ECH1', 'SEC61B', 'NACA4P', 'GHITM', 'PTGES3', 'ALDH9A1', 'ACTB', 'NDUFA1', 'GATM', 'A2M', 'NDUFB3', 'COX8A', 'CCT8', 'KARS', 'AMOT', 'CLTA', 'GADD45A', 'PSMA6', 'UMOD', 'MGP', 'ADI1', 'MT1F', 'DAD1', 'RHOC', 'SARAF', 'ATP5PF', 'SERINC1', 'PSMB1', 'ACADVL', 'TST', 'GSTO1', 'HADHB', 'HSD17B12', 'PEPD', 'LTA4H', 'SGK1', 'S100A6', 'PSMB5', 'TMED9', 'TPI1', 'TUBB2A', 'MRPL49', 'TMEM147', 'AGMAT', 'EIF4G2', 'YWHAZ', 'PHYH', 'ACAT1', 'PHB2', 'H2AFZ', 'ALDOA', 'PEBP1'], ['RPL37A', 'RPL13A', 'HLA-A', 'MT1G', 'UBB', 'GPX3', 'MT2A', 'ACTG1', 'ITM2B', 'RPS24', 'RPL5', 'MYL6', 'LDHB', 'ATP5F1A', 'RPL8', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'CD63', 'TMBIM6', 'RTN4', 'ISCU', 'CAPN2', 'HNRNPK', 'IGFBP7', 'SRP9', 'ATP5PO', 'SOD1', 'CRYAB', 'VIM', 'S100A10', 'ALDOB', 'NOP53', 'SUCLG1', 'NDUFB2', 'RHOA', 'GNAS', 'ALDH2', 'NDUFB1', 'GHITM', 'ATP5F1B', 'NEDD8', 'GABARAP', 'ACTB', 'AKR1A1', 'NACA4P', 'SPCS1', 'PTGES3', 'BHMT', 'SEC61B', 'ALDH9A1', 'ECH1', 'GATM', 'RAC1', 'NDUFA1', 'NDUFB3', 'UMOD', 'COX8A', 'ADI1', 'A2M', 'MGP', 'KARS', 'CCT8', 'GADD45A', 'PSMA6', 'TST', 'AMOT', 'SARAF', 'PSMB1', 'CLTA', 'MT1F', 'ACADVL', 'ATP5PF', 'RHOC', 'SERINC1', 'DAD1', 'HSD17B12', 'GSTO1', 'PSMB5', 'LTA4H', 'HADHB', 'TMED9', 'MRPL49', 'PEPD', 'TMEM147', 'TPI1', 'TUBB2A', 'AGMAT', 'SGK1', 'S100A6', 'UQCR10', 'SLC38A2', 'PHYH', 'FOXC1', 'ACAT1', 'CAPNS1', 'PHB2', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'GPX3', 'MT1G', 'RPS24', 'ACTG1', 'ATP5F1A', 'MT2A', 'ITM2B', 'RPL5', 'LDHB', 'MYL6', 'RPS16', 'RPL8', 'RPL15', 'IGFBP7', 'SELENOP', 'CAPN2', 'RPL38', 'RTN4', 'CD63', 'ATP5F1C', 'TMBIM6', 'HNRNPK', 'VIM', 'CRYAB', 'SRP9', 'ATP5PO', 'SOD1', 'NOP53', 'ISCU', 'S100A10', 'GHITM', 'SUCLG1', 'ATP5F1B', 'NACA4P', 'RHOA', 'ALDOB', 'NDUFB1', 'GNAS', 'NDUFB2', 'ALDH2', 'SPCS1', 'SEC61B', 'NEDD8', 'AKR1A1', 'A2M', 'NDUFB3', 'ALDH9A1', 'ECH1', 'ACTB', 'BHMT', 'RAC1', 'GABARAP', 'MT1F', 'UMOD', 'ADI1', 'NDUFA1', 'CCT8', 'PTGES3', 'COX8A', 'AMOT', 'GATM', 'MGP', 'DAD1', 'GADD45A', 'KARS', 'ACADVL', 'ATP5PF', 'PSMB1', 'SARAF', 'PSMA6', 'CLTA', 'HADHB', 'HSD17B12', 'UQCR10', 'TST', 'PEBP1', 'GSTO1', 'PSMB5', 'TMEM147', 'SDC4', 'S100A6', 'LTA4H', 'PHB2', 'TPI1', 'ADH5', 'RHOC', 'COX5B', 'ALDOA', 'SERINC1', 'SLC38A2', 'TUBB2A', 'YPEL5', 'FOXC1', 'MRPL49', 'PEPD', 'AGMAT'], ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'MT2A', 'ACTG1', 'RPS24', 'GPX3', 'ITM2B', 'RPL8', 'MYL6', 'ATP5F1A', 'RPL5', 'LDHB', 'RPL15', 'SELENOP', 'RPS16', 'TMBIM6', 'RPL38', 'ATP5F1C', 'CD63', 'ATP5PO', 'RTN4', 'VIM', 'IGFBP7', 'CAPN2', 'ISCU', 'SOD1', 'SRP9', 'HNRNPK', 'SUCLG1', 'CRYAB', 'ALDOB', 'S100A10', 'NDUFB2', 'NOP53', 'GNAS', 'RHOA', 'SPCS1', 'ALDH2', 'AKR1A1', 'GABARAP', 'BHMT', 'NEDD8', 'NDUFB1', 'SEC61B', 'ATP5F1B', 'ECH1', 'NACA4P', 'PTGES3', 'RAC1', 'GHITM', 'ACTB', 'ALDH9A1', 'COX8A', 'A2M', 'CCT8', 'NDUFA1', 'GATM', 'UMOD', 'NDUFB3', 'KARS', 'MGP', 'PSMA6', 'CLTA', 'AMOT', 'ADI1', 'GADD45A', 'DAD1', 'MT1F', 'RHOC', 'ACADVL', 'PSMB1', 'ATP5PF', 'SERINC1', 'SARAF', 'GSTO1', 'TST', 'HSD17B12', 'LTA4H', 'HADHB', 'PEPD', 'PSMB5', 'AGMAT', 'YWHAZ', 'SGK1', 'TPI1', 'TUBB2A', 'S100A6', 'TMEM147', 'TMED9', 'ACAT1', 'EIF4G2', 'MRPL49', 'PHYH', 'PHB2', 'CAPNS1', 'ANXA7', 'H2AFZ'], ['RPL13A', 'RPL37A', 'HLA-A', 'ACTG1', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'ITM2B', 'GPX3', 'RPL5', 'MYL6', 'RPL8', 'RPL15', 'ATP5F1A', 'LDHB', 'RPS16', 'TMBIM6', 'SELENOP', 'VIM', 'IGFBP7', 'RPL38', 'ATP5F1C', 'CAPN2', 'ATP5PO', 'SOD1', 'RTN4', 'CD63', 'SRP9', 'SUCLG1', 'CRYAB', 'HNRNPK', 'RHOA', 'ISCU', 'NACA4P', 'NDUFB2', 'GNAS', 'NOP53', 'ALDOB', 'S100A10', 'SEC61B', 'SPCS1', 'NDUFB1', 'AKR1A1', 'BHMT', 'RAC1', 'PTGES3', 'GHITM', 'ECH1', 'GABARAP', 'ACTB', 'ATP5F1B', 'ALDH2', 'NEDD8', 'A2M', 'ALDH9A1', 'DAD1', 'CCT8', 'COX8A', 'NDUFA1', 'AMOT', 'UMOD', 'KARS', 'GADD45A', 'PSMA6', 'MT1F', 'CLTA', 'ADI1', 'NDUFB3', 'MGP', 'ACADVL', 'GSTO1', 'RHOC', 'GATM', 'PSMB1', 'ATP5PF', 'HADHB', 'LTA4H', 'S100A6', 'PEPD', 'PSMB5', 'SARAF', 'SERINC1', 'YWHAZ', 'AGMAT', 'TPI1', 'TUBB2A', 'SDC4', 'ACAT1', 'PHB2', 'SGK1', 'TMEM147', 'HLA-DRA', 'TST', 'HSD17B12', 'PEBP1', 'ANXA7', 'EIF4G2', 'DAB2', 'CSRP1'], ['RPL13A', 'RPL37A', 'HLA-A', 'UBB', 'MT1G', 'MT2A', 'RPS24', 'GPX3', 'ACTG1', 'RPL5', 'ATP5F1A', 'ITM2B', 'MYL6', 'LDHB', 'RPS16', 'RPL15', 'RPL8', 'IGFBP7', 'RPL38', 'SELENOP', 'RTN4', 'CAPN2', 'ATP5F1C', 'VIM', 'ISCU', 'HNRNPK', 'CD63', 'ATP5PO', 'TMBIM6', 'CRYAB', 'SRP9', 'SOD1', 'NDUFB1', 'NOP53', 'ATP5F1B', 'SUCLG1', 'GHITM', 'NDUFB2', 'NACA4P', 'ALDOB', 'ALDH2', 'GNAS', 'S100A10', 'RHOA', 'A2M', 'RAC1', 'SPCS1', 'AKR1A1', 'BHMT', 'SEC61B', 'GABARAP', 'MT1F', 'COX8A', 'NDUFB3', 'NDUFA1', 'PTGES3', 'ECH1', 'ACTB', 'ADI1', 'NEDD8', 'UMOD', 'ALDH9A1', 'GADD45A', 'CCT8', 'AMOT', 'DAD1', 'MGP', 'KARS', 'ACADVL', 'GATM', 'CLTA', 'PSMA6', 'ATP5PF', 'HADHB', 'PSMB1', 'TMEM147', 'PEBP1', 'RHOC', 'PEPD', 'S100A6', 'TPI1', 'LTA4H', 'SARAF', 'GSTO1', 'UQCR10', 'HSD17B12', 'MRPL49', 'SDC4', 'SLC38A2', 'SERINC1', 'TST', 'ATOX1', 'PHB2', 'SGK1', 'PSMB5', 'COX5B', 'FOXC1', 'CSRP1', 'PAM', 'CAPNS1'], ['RPL37A', 'RPL13A', 'UBB', 'HLA-A', 'MT1G', 'GPX3', 'MT2A', 'ACTG1', 'RPL5', 'ITM2B', 'RPS24', 'MYL6', 'ATP5F1A', 'LDHB', 'RPL8', 'RPL15', 'SELENOP', 'RPS16', 'RPL38', 'ATP5F1C', 'RTN4', 'CD63', 'IGFBP7', 'CAPN2', 'HNRNPK', 'SRP9', 'ISCU', 'CRYAB', 'TMBIM6', 'VIM', 'ATP5PO', 'SOD1', 'ALDOB', 'SUCLG1', 'NOP53', 'S100A10', 'NDUFB1', 'ATP5F1B', 'GHITM', 'GNAS', 'ALDH2', 'RHOA', 'NACA4P', 'NDUFB2', 'SPCS1', 'AKR1A1', 'NEDD8', 'GABARAP', 'SEC61B', 'BHMT', 'ACTB', 'NDUFA1', 'NDUFB3', 'PTGES3', 'ALDH9A1', 'A2M', 'ECH1', 'RAC1', 'GATM', 'UMOD', 'COX8A', 'CCT8', 'MT1F', 'GADD45A', 'KARS', 'ADI1', 'AMOT', 'MGP', 'CLTA', 'ATP5PF', 'SARAF', 'ACADVL', 'PSMB1', 'PSMA6', 'DAD1', 'TST', 'HSD17B12', 'RHOC', 'GSTO1', 'SERINC1', 'HADHB', 'PEPD', 'TMEM147', 'MRPL49', 'S100A6', 'LTA4H', 'TPI1', 'UQCR10', 'PSMB5', 'FOXC1', 'TMED9', 'EIF4G2', 'PEBP1', 'AGMAT', 'TUBB2A', 'ALDOA', 'SGK1', 'PHB2', 'SLC38A2', 'PHYH'], ['RPL37A', 'RPL13A', 'UBB', 'MT1G', 'HLA-A', 'GPX3', 'MT2A', 'ACTG1', 'RPL5', 'ITM2B', 'MYL6', 'LDHB', 'RPS24', 'RPL8', 'ATP5F1A', 'RPL15', 'SELENOP', 'RPL38', 'RPS16', 'ATP5F1C', 'RTN4', 'CD63', 'ISCU', 'HNRNPK', 'TMBIM6', 'SRP9', 'CRYAB', 'CAPN2', 'VIM', 'IGFBP7', 'ATP5PO', 'SOD1', 'ALDOB', 'SUCLG1', 'NOP53', 'S100A10', 'NDUFB1', 'GNAS', 'ALDH2', 'ATP5F1B', 'NACA4P', 'SPCS1', 'GHITM', 'RHOA', 'GABARAP', 'NDUFB2', 'NEDD8', 'AKR1A1', 'SEC61B', 'BHMT', 'PTGES3', 'ACTB', 'NDUFA1', 'NDUFB3', 'A2M', 'ECH1', 'GATM', 'ALDH9A1', 'CCT8', 'RAC1', 'KARS', 'COX8A', 'GADD45A', 'UMOD', 'AMOT', 'MT1F', 'MGP', 'ADI1', 'CLTA', 'ATP5PF', 'PSMA6', 'SARAF', 'PSMB1', 'ACADVL', 'DAD1', 'TST', 'GSTO1', 'RHOC', 'HSD17B12', 'SERINC1', 'PEPD', 'MRPL49', 'HADHB', 'LTA4H', 'TMEM147', 'TMED9', 'S100A6', 'AGMAT', 'EIF4G2', 'TUBB2A', 'PSMB5', 'FOXC1', 'TPI1', 'SGK1', 'UQCR10', 'ALDOA', 'H2AFZ', 'PHYH', 'SSR4', 'ACAT1']]\n",
      "(9, 100)\n",
      "['GSTO1', 'SERINC1', 'ATP5F1C', 'BHMT', 'HLA-A', 'CLTA', 'MT1G', 'ATOX1', 'ECH1', 'PSMB1', 'RPL38', 'PAM', 'SGK1', 'SLC38A2', 'ATP5F1B', 'ISCU', 'ATP5F1A', 'TST', 'ACTG1', 'RTN4', 'RPL5', 'ALDH9A1', 'ALDH2', 'PTGES3', 'CAPN2', 'DAB2', 'AKR1A1', 'RPS16', 'RPL15', 'NDUFA1', 'PHB2', 'NDUFB3', 'LTA4H', 'MT1F', 'CSRP1', 'ACAT1', 'SSR4', 'GNAS', 'CAPNS1', 'A2M', 'VIM', 'RHOC', 'MT2A', 'KARS', 'FOXC1', 'ANXA7', 'ALDOB', 'RHOA', 'ADI1', 'TMBIM6', 'SOD1', 'NDUFB1', 'RPL37A', 'PEBP1', 'ADH5', 'MGP', 'UBB', 'HLA-DRA', 'GABARAP', 'ALDOA', 'TMED9', 'PSMA6', 'SEC61B', 'RAC1', 'YPEL5', 'HSD17B12', 'PSMB5', 'ACADVL', 'MYL6', 'NACA4P', 'CCT8', 'EIF4G2', 'TPI1', 'ITM2B', 'GHITM', 'GADD45A', 'COX5B', 'HNRNPK', 'COX8A', 'TUBB2A', 'PEPD', 'ATP5PO', 'NEDD8', 'CRYAB', 'ACTB', 'ATP5PF', 'GATM', 'SUCLG1', 'RPL13A', 'SELENOP', 'CD63', 'SRP9', 'YWHAZ', 'GPX3', 'RPL8', 'S100A10', 'DAD1', 'RPS24', 'NDUFB2', 'SARAF', 'TMEM147', 'AMOT', 'IGFBP7', 'PSME1', 'MRPL49', 'SPCS1', 'UMOD', 'S100A6', 'SDC4', 'H2AFZ', 'PHYH', 'HADHB', 'NOP53', 'UQCR10', 'LDHB', 'AGMAT']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'RHOA', 'STX2', 'CISD1', 'WDR11', 'SCYL2', 'MGC2889',\n",
      "       'CCDC47', 'KLF8', 'CCL1',\n",
      "       ...\n",
      "       'PLAC4', 'NRBP1', 'LRRC23', 'SPHK2', 'KIAA0513', 'SULT1A1', 'AMOT',\n",
      "       'CA1', 'GPR35', 'label'],\n",
      "      dtype='object', length=3302)\n",
      "['GSTO1', 'SERINC1', 'ATP5F1C', 'BHMT', 'HLA-A', 'CLTA', 'MT1G', 'ATOX1', 'ECH1', 'PSMB1', 'RPL38', 'PAM', 'SGK1', 'SLC38A2', 'ATP5F1B', 'ISCU', 'ATP5F1A', 'TST', 'ACTG1', 'RTN4', 'RPL5', 'ALDH9A1', 'ALDH2', 'PTGES3', 'CAPN2', 'DAB2', 'AKR1A1', 'RPS16', 'RPL15', 'NDUFA1', 'PHB2', 'NDUFB3', 'LTA4H', 'MT1F', 'CSRP1', 'ACAT1', 'SSR4', 'GNAS', 'CAPNS1', 'A2M', 'VIM', 'RHOC', 'MT2A', 'KARS', 'FOXC1', 'ANXA7', 'ALDOB', 'RHOA', 'ADI1', 'TMBIM6', 'SOD1', 'NDUFB1', 'RPL37A', 'PEBP1', 'ADH5', 'MGP', 'UBB', 'HLA-DRA', 'GABARAP', 'ALDOA', 'TMED9', 'PSMA6', 'SEC61B', 'RAC1', 'YPEL5', 'HSD17B12', 'PSMB5', 'ACADVL', 'MYL6', 'NACA4P', 'CCT8', 'EIF4G2', 'TPI1', 'ITM2B', 'GHITM', 'GADD45A', 'COX5B', 'HNRNPK', 'COX8A', 'TUBB2A', 'PEPD', 'ATP5PO', 'NEDD8', 'CRYAB', 'ACTB', 'ATP5PF', 'GATM', 'SUCLG1', 'RPL13A', 'SELENOP', 'CD63', 'SRP9', 'YWHAZ', 'GPX3', 'RPL8', 'S100A10', 'DAD1', 'RPS24', 'NDUFB2', 'SARAF', 'TMEM147', 'AMOT', 'IGFBP7', 'PSME1', 'MRPL49', 'SPCS1', 'UMOD', 'S100A6', 'SDC4', 'H2AFZ', 'PHYH', 'HADHB', 'NOP53', 'UQCR10', 'LDHB', 'AGMAT', 'label']\n",
      "(549, 117)\n",
      "(138, 117)\n"
     ]
    }
   ],
   "source": [
    "#top_20\n",
    "\n",
    "\n",
    "#compute mean value of all the correctly predicted samples:\n",
    "import pandas as pd \n",
    "import torch\n",
    "import numpy as np\n",
    "test_df=pd.read_csv('dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/ConvAttMLP_10layers_add//test_info3.csv',sep=',')\n",
    "test_df=test_df.iloc[:,1:]\n",
    "rows,cols=test_df.shape\n",
    "#print(rows,cols)\n",
    "columns=test_df.columns[:-1].tolist()\n",
    "#columns=torch.tensor(columns).cuda()#ValueError: too many dimensions 'str'\n",
    "\n",
    "\n",
    "row_mean=test_df.mean(axis=0)\n",
    "#print(row_mean)\n",
    "row_mean=row_mean[:-1]#drop off label\n",
    "row_mean_np=np.array(row_mean).reshape(1,-1)\n",
    "#print(row_mean_np)\n",
    "row_mean_df=pd.DataFrame(row_mean_np)\n",
    "#print(row_mean_df)\n",
    "row_mean_df.columns=test_df.columns[:-1]\n",
    "#print(row_mean_df)\n",
    "row_mean_tensor=torch.from_numpy(row_mean_np).cuda()\n",
    "row_mean_tensor=torch.tensor(row_mean_tensor,dtype=torch.float)###################################\n",
    "#去掉行\n",
    "#print('row_mean_tensor:',row_mean_tensor.shape)\n",
    "\n",
    "row_mean_tensor.cuda()\n",
    "#print('x_bn0:',x.shape)\n",
    "#x2=torch.zeros([1,1100])\n",
    "#x2=x2.cuda()\n",
    "#xm=torch.cat([row_mean_tensor,x2],dim=1)\n",
    "\n",
    "#compute contribution using the Equ.\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "path='models/ConvAttMLP_10layers_add/MLP310.pt'\n",
    "\n",
    "#nfm=NFM(nfm_config)\n",
    "model=ConvAttMLP_10layers_add()\n",
    "model_lrp=ConvAttMLP_10layers_add_LRP()\n",
    "#print(nfm)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "# Load the state_dict for both models separately\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(path), strict=False)\n",
    "'''\n",
    "# 将原始网络的参数赋值给子网络\n",
    "for param_name, param in model.named_parameters():\n",
    "    if hasattr(model_lrp, param_name):\n",
    "        sub_param = getattr(model_lrp, param_name)\n",
    "        if sub_param.data.shape == param.data.shape:\n",
    "            sub_param.data = param.data.clone()\n",
    "'''            \n",
    "#model_lrp.named_parameters['fc22.weight']=model.named_parameters['fc2.weight'][:,:1100]\n",
    "#model_lrp.named_parameters['fc22.bias']=model.named_parameters['fc2.bias']\n",
    "model_lrp.fc22.weight.data=model.fc2.weight.data[:,:1100]\n",
    "\n",
    "'''            \n",
    "# 输出模型的参数名和参数形状\n",
    "for name, param in model_lrp.named_parameters():\n",
    "    print(f\"Parameter Name: {name}, Shape: {param.size()}\")\n",
    "'''            \n",
    "            \n",
    "#model_lrp.load_state_dict(model.state_dict())  # Copying the loaded state dict to model_lrp\n",
    "\n",
    "model.cuda()\n",
    "model_lrp.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    n = len(labels)\n",
    "    #n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline\n",
    "\n",
    "from innvestigator2 import InnvestigateModel\n",
    "#from utils import Flatten\n",
    "model.double()\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "inn_model = InnvestigateModel(model_lrp, lrp_exponent=2,\n",
    "                              method=\"e-rule\",\n",
    "                              beta=.5)\n",
    "\n",
    "genes_features=np.array([i for i  in range(9)])#################\n",
    "genes_features=genes_features.reshape(9,1).tolist()#######################genes_features[i][0]=label\n",
    "\n",
    "inn_model.cuda()\n",
    "\n",
    "###[3, 25.353026075712233, tensor([ 182,  879,  103, 2657, 2489,  914, 2437,  180, 2417, 1402, 2344, 2947,\n",
    "###values=tensor([0.0572, 0.0495, 0.0404, 0.0381, 0.0364, 0.0353, 0.0328, 0.0302, 0.0284,\n",
    "#        0.0257, 0.0180, 0.0164, 0.0155, 0.0150, 0.0135, 0.0127, 0.0121, 0.0120,\n",
    "#        0.0114, 0.0107, 0.0107, 0.0104, 0.0100, 0.0100, 0.0099, 0.0091, 0.0091,\n",
    "#       0.0088, 0.0083, 0.0082, 0.0081, 0.0079, 0.0078, 0.0077, 0.0076, 0.0074,\n",
    "#       0.0073, 0.0072, 0.0072, 0.0071], dtype=torch.float64),\n",
    "###indices=tensor([ 182,  879,  103, 2657, 2489,  914, 2437,  180, 2417, 1402, 2344, 2947,\n",
    "#        2546, 1114,  796, 1111, 2472, 2326, 1274,  932, 2476,  716,  989, 3289,\n",
    "#        1252, 2053,  785, 2429, 3015, 1585,  975, 1150, 1155,  726,  823, 2303,\n",
    "#         699,  349, 1792, 1524])), 25.359040192320702, tensor([2489,  826, 1753, 1792,  601, 2303, 1053,  545, 2559,  624, 3256,  762,\n",
    "#        2666,  182, 1881, 1585,  726, 1367, 2405, 1171, 2947, 2093,   14,  265,\n",
    "#         716,  180, 1467, 2207, 3223,  349,  277, 2141, 2878, 2427, 2326, 1111,\n",
    "#         746, 1402, 2150, 1602]), torch.return_types.topk(\n",
    "#values=tensor([0.0456, 0.0445, 0.0406, 0.0349, 0.0277, 0.0273, 0.0246, 0.0236, 0.0225,\n",
    "#        0.0221, 0.0213, 0.0200, 0.0185, 0.0182, 0.0181, 0.0153, 0.0151, 0.0142,\n",
    "##        0.0141, 0.0140, 0.0138, 0.0123, 0.0121, 0.0115, 0.0109, 0.0108, 0.0107,\n",
    "#        0.0102, 0.0102, 0.0098, 0.0094, 0.0093, 0.0092, 0.0089, 0.0082, 0.0081,\n",
    "#        0.0080, 0.0080, 0.0079, 0.0076], dtype=torch.float64),\n",
    "#indices=tensor([2489,  826, 1753, 1792,  601, 2303, 1053,  545, 2559,  624, 3256,  762,\n",
    "#        2666,  182, 1881, 1585,  726, 1367, 2405, 1171, 2947, 2093,   14,  265,\n",
    "#         716,  180, 1467, 2207, 3223,  349,  277, 2141, 2878, 2427, 2326, 1111,\n",
    "#         746, 1402, 2150, 1602]))]\n",
    "\n",
    "row_mean_tensor=row_mean_tensor.cuda()\n",
    "#print('batch_size:',batch_size)#=20\n",
    "evidence_for_class = []\n",
    "#print(\"target:\",target.shape)\n",
    "#print('target:',target[3])\n",
    "# Overlay with noise \n",
    "# data[0] += 0.25 * data[0].max() * torch.Tensor(np.random.randn(28*28).reshape(1, 28, 28))\n",
    "#model_prediction, true_relevance = inn_model.innvestigate(in_tensor=data)\n",
    "contri_k=[]\n",
    "contri_k_names=[]\n",
    "for i in range(9):#10类\n",
    "    # Unfortunately, we had some issue with freeing pytorch memory, therefore \n",
    "    # we need to reevaluate the model separately for every class.\n",
    "        model_prediction, input_relevance_values = inn_model.innvestigate(in_tensor=row_mean_tensor)\n",
    "        #model_prediction, input_relevance_values = inn_model.innvestigate(in_tensor=xm)\n",
    "        evidence_for_class.append(input_relevance_values)\n",
    "        top_k=torch.topk(input_relevance_values,100,largest=True)#################20\n",
    "        print('top_k:',top_k)\n",
    "    \n",
    "        contri_k.append(top_k)\n",
    "        top_k_indices=top_k.indices.cpu().detach().numpy().tolist()\n",
    "        print('top_k_indices:',top_k_indices)\n",
    "        # 将二维列表转换为一维列表\n",
    "        flattened_indices = [item for sublist in top_k_indices for item in sublist]\n",
    "\n",
    "        top_k_names=[columns[j] for j in flattened_indices]\n",
    "        print('top_k_names:',top_k_names)\n",
    "        contri_k_names.append(top_k_names)\n",
    "        print('contri_k_names:',contri_k_names)\n",
    "        \n",
    "print('begin=============================')\n",
    "l=contri_k_names[4]\n",
    "l1=contri_k_names[0]\n",
    "for i in contri_k_names:\n",
    "    if i!=\n",
    "    s1=set1.intersection(set2)\n",
    "\n",
    "print('end=================================')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "contri_k_names_np=np.array(contri_k_names)\n",
    "print(contri_k_names_np.shape)\n",
    "\n",
    "contri_k_names_df=pd.DataFrame(contri_k_names_np)\n",
    "contri_k_names_df.to_csv('results_genes/ConvAttMLP_10layers_add//LRP/contri_100_names_df.csv')\n",
    "#from chartGPT of the following code\n",
    "result = set()\n",
    "for sublist in contri_k_names:\n",
    "    result = result.union(sublist)\n",
    "\n",
    "# 或者使用集合的union方法的更简洁写法，使用集合解析\n",
    "# result = set().union(*list_of_lists)\n",
    "\n",
    "# 或者使用 | 运算符\n",
    "# result = set().union(*list_of_lists)\n",
    "\n",
    "# 将结果转回列表\n",
    "result_list = list(result)\n",
    "\n",
    "print(result_list)\n",
    "\n",
    "import csv\n",
    "csv_filename = \"results_genes/ConvAttMLP_10layers_add//LRP/genes_all_100_mean.csv\"\n",
    "\n",
    "# 使用CSV模块保存列表为CSV文件\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    writer.writerow(result_list)\n",
    "\n",
    "#这将输出所有列表的并集，不包含重复的元素。在这个例子中，结果会是 [1, 2, 3, 4, 5, 6, 7]。你可以根据你的实际需求将这个结果转换为列表或者保留为集合，具体取决于你的应用场景。\n",
    "#抽取训练集和测试集中的数据\n",
    "\n",
    "#生成新选取元素的数据集\n",
    "train_path='dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/train_val_info.csv'\n",
    "test_path='dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/test_info.csv'\n",
    "\n",
    "train_df=pd.read_csv(train_path,sep=',')\n",
    "train_df1=train_df\n",
    "print(train_df1.columns)\n",
    "train_df=train_df.iloc[:,1:]\n",
    "train_df1=train_df1.iloc[:,1:-1]\n",
    "\n",
    "columns=result_list\n",
    "columns.append('label')\n",
    "print(columns)\n",
    "\n",
    "\n",
    "train_df2=train_df[columns]\n",
    "print(train_df2.shape)\n",
    "train_df2.to_csv('dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/ConvAttMLP_10layers_add//LRP/train_val_info_100.csv')\n",
    "\n",
    "test_df=pd.read_csv(test_path,sep=',')\n",
    "\n",
    "test_df=test_df.iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "test_df=test_df[columns]\n",
    "print(test_df.shape)\n",
    "test_df.to_csv('dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/ConvAttMLP_10layers_add//LRP/test_info_100.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d164d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3300])\n"
     ]
    }
   ],
   "source": [
    "x=torch.zeros([1, 3300])\n",
    "y=torch.squeeze(x,0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df55a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
